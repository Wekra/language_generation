{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprachgenerierung\n",
    "\n",
    "Auch in dieser Woche besch√§ftigen wir uns mit Twitter-Daten. Diesmal geht es jedoch nicht um Sentiment Analysis, sondern wir wollen ein Modell trainieren, das es uns erlaubt, Tweets in einem bestimmten Stil zu generieren.\n",
    "\n",
    "Als Datengrundlage dienen uns Daten von http://www.trumptwitterarchive.com. Brendan Brown, der Betreiber der Seite hat s√§mtliche Tweets von Donald Trump seit Mai 2009 zusammengetragen. Da wir die Sprache des US-Pr√§sidenten modellieren wollen, verwenden wir nur dessen eigene und keine Retweets.\n",
    "\n",
    "Unser Modell wird auf der Ebene von Einzelzeichen arbeiten, zun√§chst wollen wir uns aber auf einer h√∂heren Ebene einen √úberblick √ºber den Datensatz verschaffen.\n",
    "\n",
    "## 1. Aufgabe: √úberblick √ºber den Datensatz\n",
    "### 1.1 Datensatz einlesen\n",
    "Lest den in der Datei ```all_tweets.json``` enthaltenen Datensatz in einen Pandas-Dataframe mit folgenden Spalten ein: ```created_at```, ```id```, ```text```. Die √ºbrigen im JSON enthaltenen Felder k√∂nnen ignoriert werden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun Apr 28 12:59:53 +0000 2019</td>\n",
       "      <td>1122485588580605953</td>\n",
       "      <td>Will be interviewed by @MariaBartiromo on @Fox...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun Apr 28 03:10:25 +0000 2019</td>\n",
       "      <td>1122337243744497664</td>\n",
       "      <td>....for the more traditional, but not very bri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sun Apr 28 03:10:24 +0000 2019</td>\n",
       "      <td>1122337240330297344</td>\n",
       "      <td>The Democratic National Committee, sometimes r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Apr 28 02:57:32 +0000 2019</td>\n",
       "      <td>1122334000519868416</td>\n",
       "      <td>....Ever since Andrew came to my office to ask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun Apr 28 02:57:31 +0000 2019</td>\n",
       "      <td>1122333996451418112</td>\n",
       "      <td>Thank you to brilliant and highly respected at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sun Apr 28 02:07:11 +0000 2019</td>\n",
       "      <td>1122321330282561536</td>\n",
       "      <td>Thank you Green Bay, Wisconsin! MAKE AMERICA G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sun Apr 28 01:58:39 +0000 2019</td>\n",
       "      <td>1122319181221892096</td>\n",
       "      <td>Beautiful #TrumpRally tonight in Green Bay, Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sat Apr 27 23:46:06 +0000 2019</td>\n",
       "      <td>1122285823473401857</td>\n",
       "      <td>Just arrived in Green Bay, Wisconsin for a #MA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sat Apr 27 22:47:01 +0000 2019</td>\n",
       "      <td>1122270956192272385</td>\n",
       "      <td>Sincerest THANK YOU to our great Border Patrol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sat Apr 27 22:14:25 +0000 2019</td>\n",
       "      <td>1122262750531477504</td>\n",
       "      <td>Great day with Prime Minister @AbeShinzo of Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sat Apr 27 22:00:23 +0000 2019</td>\n",
       "      <td>1122259220215164928</td>\n",
       "      <td>Leaving now for Green Bay, Wisconsin - BIG CRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sat Apr 27 21:41:05 +0000 2019</td>\n",
       "      <td>1122254362175332355</td>\n",
       "      <td>Thoughts and prayers to all of those affected ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sat Apr 27 17:05:36 +0000 2019</td>\n",
       "      <td>1122185034281172994</td>\n",
       "      <td>We must end the Opioid Crisis. Do your part to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sat Apr 27 16:41:38 +0000 2019</td>\n",
       "      <td>1122179005715820546</td>\n",
       "      <td>We must end the Opioid Crisis. Do your part to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sat Apr 27 12:06:03 +0000 2019</td>\n",
       "      <td>1122109651087241216</td>\n",
       "      <td>Congratulations to Nick Bosa on being picked n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fri Apr 26 22:57:34 +0000 2019</td>\n",
       "      <td>1121911223212285953</td>\n",
       "      <td>THANK YOU @NRA! #NRAAM https://t.co/SWkpe1eFhT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fri Apr 26 19:13:29 +0000 2019</td>\n",
       "      <td>1121854831327621125</td>\n",
       "      <td>‚ÄúU.S. Economy Grows 3.2% in Q1, Smashing Expec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fri Apr 26 18:31:47 +0000 2019</td>\n",
       "      <td>1121844339200540672</td>\n",
       "      <td>Spoke to Saudi Arabia and others about increas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fri Apr 26 17:34:33 +0000 2019</td>\n",
       "      <td>1121829933679042565</td>\n",
       "      <td>Great NRA crowd and enthusiasm in Indiana. Tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fri Apr 26 14:25:28 +0000 2019</td>\n",
       "      <td>1121782348469522435</td>\n",
       "      <td>Just out: Real GDP for First Quarter grew 3.2%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Fri Apr 26 12:47:07 +0000 2019</td>\n",
       "      <td>1121757597139439618</td>\n",
       "      <td>Heading to Indianapolis to speak at the big NR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Fri Apr 26 12:39:55 +0000 2019</td>\n",
       "      <td>1121755785246195712</td>\n",
       "      <td>Weirdo Tom Steyer, who didn‚Äôt have the ‚Äúguts‚Äù ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Fri Apr 26 11:32:40 +0000 2019</td>\n",
       "      <td>1121738863486095360</td>\n",
       "      <td>‚ÄúPresident Donald J. Trump is the greatest hos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Fri Apr 26 11:12:21 +0000 2019</td>\n",
       "      <td>1121733749757087750</td>\n",
       "      <td>No money was paid to North Korea for Otto Warm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Fri Apr 26 00:59:14 +0000 2019</td>\n",
       "      <td>1121579455330254850</td>\n",
       "      <td>I will be interviewed on @seanhannity at 9:00 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Thu Apr 25 18:11:16 +0000 2019</td>\n",
       "      <td>1121476784376225798</td>\n",
       "      <td>Thank you! #MAGAüá∫üá∏ https://t.co/EWjwRlmIve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Thu Apr 25 18:09:25 +0000 2019</td>\n",
       "      <td>1121476321882902529</td>\n",
       "      <td>Our Border Control Agents have done an incredi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Thu Apr 25 16:32:44 +0000 2019</td>\n",
       "      <td>1121451990712762369</td>\n",
       "      <td>Look forward to seeing everyone in Indianapoli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Thu Apr 25 14:35:11 +0000 2019</td>\n",
       "      <td>1121422408420855810</td>\n",
       "      <td>I will be interviewed by @seanhannity tonight ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Thu Apr 25 12:22:18 +0000 2019</td>\n",
       "      <td>1121388967444799488</td>\n",
       "      <td>Welcome to the race Sleepy Joe. I only hope yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25665</th>\n",
       "      <td>Wed Jun 24 22:09:19 +0000 2009</td>\n",
       "      <td>2317112756</td>\n",
       "      <td>Donald Trump‚Äôs commercial-free WWE Raw does bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25666</th>\n",
       "      <td>Tue Jun 23 13:40:38 +0000 2009</td>\n",
       "      <td>2294519255</td>\n",
       "      <td>‚ÄúExpand your life every day.‚Äù ‚ÄìDonald J. Trump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25667</th>\n",
       "      <td>Sun Jun 21 14:47:41 +0000 2009</td>\n",
       "      <td>2266041769</td>\n",
       "      <td>- Wishing a Happy Father's Day to all the Dad'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25668</th>\n",
       "      <td>Thu Jun 18 13:26:53 +0000 2009</td>\n",
       "      <td>2222067805</td>\n",
       "      <td>RE: FB Vanity URLs: SF Chronicle - \"David Beck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25669</th>\n",
       "      <td>Mon Jun 15 23:13:05 +0000 2009</td>\n",
       "      <td>2184650461</td>\n",
       "      <td>Thanks to all for your thoughtful birthday wis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25670</th>\n",
       "      <td>Sun Jun 14 14:25:36 +0000 2009</td>\n",
       "      <td>2165353946</td>\n",
       "      <td>Today is Donald Trump's Birthday! Send him you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25671</th>\n",
       "      <td>Mon Jun 08 20:15:29 +0000 2009</td>\n",
       "      <td>2080633709</td>\n",
       "      <td>Last week to enter the \"Think Like A Champion\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25672</th>\n",
       "      <td>Fri Jun 05 18:21:37 +0000 2009</td>\n",
       "      <td>2045871770</td>\n",
       "      <td>‚ÄúIf you don't have problems, you're pretending...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25673</th>\n",
       "      <td>Wed Jun 03 18:19:49 +0000 2009</td>\n",
       "      <td>2019316195</td>\n",
       "      <td>Check out Donald Trump's new iGoogle Showcase ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25674</th>\n",
       "      <td>Thu May 28 18:03:34 +0000 2009</td>\n",
       "      <td>1949899014</td>\n",
       "      <td>\"You have to know when to call it quits and wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25675</th>\n",
       "      <td>Wed May 27 14:18:52 +0000 2009</td>\n",
       "      <td>1936022874</td>\n",
       "      <td>Read an excerpt from Think Like A Champion by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25676</th>\n",
       "      <td>Tue May 26 14:42:01 +0000 2009</td>\n",
       "      <td>1924074459</td>\n",
       "      <td>\"Your higher self is in direct opposition to y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25677</th>\n",
       "      <td>Sat May 23 16:11:19 +0000 2009</td>\n",
       "      <td>1894284587</td>\n",
       "      <td>Did you know Donald Trump is on Facebook? http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25678</th>\n",
       "      <td>Fri May 22 16:28:34 +0000 2009</td>\n",
       "      <td>1884022748</td>\n",
       "      <td>Don't forget to enter the \"Think Like A Champi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25679</th>\n",
       "      <td>Fri May 22 02:59:39 +0000 2009</td>\n",
       "      <td>1878373267</td>\n",
       "      <td>\"Keep it fast, short and direct - whatever it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25680</th>\n",
       "      <td>Wed May 20 22:29:47 +0000 2009</td>\n",
       "      <td>1864367186</td>\n",
       "      <td>Read a great interview with Donald Trump that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25681</th>\n",
       "      <td>Wed May 20 13:25:39 +0000 2009</td>\n",
       "      <td>1859044981</td>\n",
       "      <td>\"Always know you could be on the precipice of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25682</th>\n",
       "      <td>Tue May 19 17:43:39 +0000 2009</td>\n",
       "      <td>1849558306</td>\n",
       "      <td>\"...these days...we could all use a little of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25683</th>\n",
       "      <td>Mon May 18 14:26:00 +0000 2009</td>\n",
       "      <td>1836131903</td>\n",
       "      <td>\"We win in our lives by having a champion's vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25684</th>\n",
       "      <td>Sun May 17 15:00:03 +0000 2009</td>\n",
       "      <td>1826225450</td>\n",
       "      <td>\"Don‚Äôt be afraid of being unique - it's like b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25685</th>\n",
       "      <td>Sat May 16 22:22:45 +0000 2009</td>\n",
       "      <td>1820624395</td>\n",
       "      <td>\"When the achiever achieves, it's not a platea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25686</th>\n",
       "      <td>Fri May 15 14:13:13 +0000 2009</td>\n",
       "      <td>1806258917</td>\n",
       "      <td>Enter the \"Think Like A Champion\" signed book ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25687</th>\n",
       "      <td>Thu May 14 16:30:40 +0000 2009</td>\n",
       "      <td>1796477499</td>\n",
       "      <td>\"Strive for wholeness and keep your sense of w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25688</th>\n",
       "      <td>Wed May 13 17:38:28 +0000 2009</td>\n",
       "      <td>1786560616</td>\n",
       "      <td>Listen to an interview with Donald Trump discu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25689</th>\n",
       "      <td>Tue May 12 19:21:55 +0000 2009</td>\n",
       "      <td>1776419923</td>\n",
       "      <td>Miss USA Tara Conner will not be fired - \"I've...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25690</th>\n",
       "      <td>Tue May 12 14:07:28 +0000 2009</td>\n",
       "      <td>1773561338</td>\n",
       "      <td>\"My persona will never be that of a wallflower...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25691</th>\n",
       "      <td>Fri May 08 20:40:15 +0000 2009</td>\n",
       "      <td>1741160716</td>\n",
       "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25692</th>\n",
       "      <td>Fri May 08 13:38:08 +0000 2009</td>\n",
       "      <td>1737479987</td>\n",
       "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25693</th>\n",
       "      <td>Tue May 05 01:00:10 +0000 2009</td>\n",
       "      <td>1701461182</td>\n",
       "      <td>Donald Trump will be appearing on The View tom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25694</th>\n",
       "      <td>Mon May 04 18:54:25 +0000 2009</td>\n",
       "      <td>1698308935</td>\n",
       "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25695 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           created_at               id_str  \\\n",
       "0      Sun Apr 28 12:59:53 +0000 2019  1122485588580605953   \n",
       "1      Sun Apr 28 03:10:25 +0000 2019  1122337243744497664   \n",
       "2      Sun Apr 28 03:10:24 +0000 2019  1122337240330297344   \n",
       "3      Sun Apr 28 02:57:32 +0000 2019  1122334000519868416   \n",
       "4      Sun Apr 28 02:57:31 +0000 2019  1122333996451418112   \n",
       "5      Sun Apr 28 02:07:11 +0000 2019  1122321330282561536   \n",
       "6      Sun Apr 28 01:58:39 +0000 2019  1122319181221892096   \n",
       "7      Sat Apr 27 23:46:06 +0000 2019  1122285823473401857   \n",
       "8      Sat Apr 27 22:47:01 +0000 2019  1122270956192272385   \n",
       "9      Sat Apr 27 22:14:25 +0000 2019  1122262750531477504   \n",
       "10     Sat Apr 27 22:00:23 +0000 2019  1122259220215164928   \n",
       "11     Sat Apr 27 21:41:05 +0000 2019  1122254362175332355   \n",
       "12     Sat Apr 27 17:05:36 +0000 2019  1122185034281172994   \n",
       "13     Sat Apr 27 16:41:38 +0000 2019  1122179005715820546   \n",
       "14     Sat Apr 27 12:06:03 +0000 2019  1122109651087241216   \n",
       "15     Fri Apr 26 22:57:34 +0000 2019  1121911223212285953   \n",
       "16     Fri Apr 26 19:13:29 +0000 2019  1121854831327621125   \n",
       "17     Fri Apr 26 18:31:47 +0000 2019  1121844339200540672   \n",
       "18     Fri Apr 26 17:34:33 +0000 2019  1121829933679042565   \n",
       "19     Fri Apr 26 14:25:28 +0000 2019  1121782348469522435   \n",
       "20     Fri Apr 26 12:47:07 +0000 2019  1121757597139439618   \n",
       "21     Fri Apr 26 12:39:55 +0000 2019  1121755785246195712   \n",
       "22     Fri Apr 26 11:32:40 +0000 2019  1121738863486095360   \n",
       "23     Fri Apr 26 11:12:21 +0000 2019  1121733749757087750   \n",
       "24     Fri Apr 26 00:59:14 +0000 2019  1121579455330254850   \n",
       "25     Thu Apr 25 18:11:16 +0000 2019  1121476784376225798   \n",
       "26     Thu Apr 25 18:09:25 +0000 2019  1121476321882902529   \n",
       "27     Thu Apr 25 16:32:44 +0000 2019  1121451990712762369   \n",
       "28     Thu Apr 25 14:35:11 +0000 2019  1121422408420855810   \n",
       "29     Thu Apr 25 12:22:18 +0000 2019  1121388967444799488   \n",
       "...                               ...                  ...   \n",
       "25665  Wed Jun 24 22:09:19 +0000 2009           2317112756   \n",
       "25666  Tue Jun 23 13:40:38 +0000 2009           2294519255   \n",
       "25667  Sun Jun 21 14:47:41 +0000 2009           2266041769   \n",
       "25668  Thu Jun 18 13:26:53 +0000 2009           2222067805   \n",
       "25669  Mon Jun 15 23:13:05 +0000 2009           2184650461   \n",
       "25670  Sun Jun 14 14:25:36 +0000 2009           2165353946   \n",
       "25671  Mon Jun 08 20:15:29 +0000 2009           2080633709   \n",
       "25672  Fri Jun 05 18:21:37 +0000 2009           2045871770   \n",
       "25673  Wed Jun 03 18:19:49 +0000 2009           2019316195   \n",
       "25674  Thu May 28 18:03:34 +0000 2009           1949899014   \n",
       "25675  Wed May 27 14:18:52 +0000 2009           1936022874   \n",
       "25676  Tue May 26 14:42:01 +0000 2009           1924074459   \n",
       "25677  Sat May 23 16:11:19 +0000 2009           1894284587   \n",
       "25678  Fri May 22 16:28:34 +0000 2009           1884022748   \n",
       "25679  Fri May 22 02:59:39 +0000 2009           1878373267   \n",
       "25680  Wed May 20 22:29:47 +0000 2009           1864367186   \n",
       "25681  Wed May 20 13:25:39 +0000 2009           1859044981   \n",
       "25682  Tue May 19 17:43:39 +0000 2009           1849558306   \n",
       "25683  Mon May 18 14:26:00 +0000 2009           1836131903   \n",
       "25684  Sun May 17 15:00:03 +0000 2009           1826225450   \n",
       "25685  Sat May 16 22:22:45 +0000 2009           1820624395   \n",
       "25686  Fri May 15 14:13:13 +0000 2009           1806258917   \n",
       "25687  Thu May 14 16:30:40 +0000 2009           1796477499   \n",
       "25688  Wed May 13 17:38:28 +0000 2009           1786560616   \n",
       "25689  Tue May 12 19:21:55 +0000 2009           1776419923   \n",
       "25690  Tue May 12 14:07:28 +0000 2009           1773561338   \n",
       "25691  Fri May 08 20:40:15 +0000 2009           1741160716   \n",
       "25692  Fri May 08 13:38:08 +0000 2009           1737479987   \n",
       "25693  Tue May 05 01:00:10 +0000 2009           1701461182   \n",
       "25694  Mon May 04 18:54:25 +0000 2009           1698308935   \n",
       "\n",
       "                                                    text  \n",
       "0      Will be interviewed by @MariaBartiromo on @Fox...  \n",
       "1      ....for the more traditional, but not very bri...  \n",
       "2      The Democratic National Committee, sometimes r...  \n",
       "3      ....Ever since Andrew came to my office to ask...  \n",
       "4      Thank you to brilliant and highly respected at...  \n",
       "5      Thank you Green Bay, Wisconsin! MAKE AMERICA G...  \n",
       "6      Beautiful #TrumpRally tonight in Green Bay, Wi...  \n",
       "7      Just arrived in Green Bay, Wisconsin for a #MA...  \n",
       "8      Sincerest THANK YOU to our great Border Patrol...  \n",
       "9      Great day with Prime Minister @AbeShinzo of Ja...  \n",
       "10     Leaving now for Green Bay, Wisconsin - BIG CRO...  \n",
       "11     Thoughts and prayers to all of those affected ...  \n",
       "12     We must end the Opioid Crisis. Do your part to...  \n",
       "13     We must end the Opioid Crisis. Do your part to...  \n",
       "14     Congratulations to Nick Bosa on being picked n...  \n",
       "15        THANK YOU @NRA! #NRAAM https://t.co/SWkpe1eFhT  \n",
       "16     ‚ÄúU.S. Economy Grows 3.2% in Q1, Smashing Expec...  \n",
       "17     Spoke to Saudi Arabia and others about increas...  \n",
       "18     Great NRA crowd and enthusiasm in Indiana. Tha...  \n",
       "19     Just out: Real GDP for First Quarter grew 3.2%...  \n",
       "20     Heading to Indianapolis to speak at the big NR...  \n",
       "21     Weirdo Tom Steyer, who didn‚Äôt have the ‚Äúguts‚Äù ...  \n",
       "22     ‚ÄúPresident Donald J. Trump is the greatest hos...  \n",
       "23     No money was paid to North Korea for Otto Warm...  \n",
       "24     I will be interviewed on @seanhannity at 9:00 ...  \n",
       "25            Thank you! #MAGAüá∫üá∏ https://t.co/EWjwRlmIve  \n",
       "26     Our Border Control Agents have done an incredi...  \n",
       "27     Look forward to seeing everyone in Indianapoli...  \n",
       "28     I will be interviewed by @seanhannity tonight ...  \n",
       "29     Welcome to the race Sleepy Joe. I only hope yo...  \n",
       "...                                                  ...  \n",
       "25665  Donald Trump‚Äôs commercial-free WWE Raw does bi...  \n",
       "25666  ‚ÄúExpand your life every day.‚Äù ‚ÄìDonald J. Trump...  \n",
       "25667  - Wishing a Happy Father's Day to all the Dad'...  \n",
       "25668  RE: FB Vanity URLs: SF Chronicle - \"David Beck...  \n",
       "25669  Thanks to all for your thoughtful birthday wis...  \n",
       "25670  Today is Donald Trump's Birthday! Send him you...  \n",
       "25671  Last week to enter the \"Think Like A Champion\"...  \n",
       "25672  ‚ÄúIf you don't have problems, you're pretending...  \n",
       "25673  Check out Donald Trump's new iGoogle Showcase ...  \n",
       "25674  \"You have to know when to call it quits and wh...  \n",
       "25675  Read an excerpt from Think Like A Champion by ...  \n",
       "25676  \"Your higher self is in direct opposition to y...  \n",
       "25677  Did you know Donald Trump is on Facebook? http...  \n",
       "25678  Don't forget to enter the \"Think Like A Champi...  \n",
       "25679  \"Keep it fast, short and direct - whatever it ...  \n",
       "25680  Read a great interview with Donald Trump that ...  \n",
       "25681  \"Always know you could be on the precipice of ...  \n",
       "25682  \"...these days...we could all use a little of ...  \n",
       "25683  \"We win in our lives by having a champion's vi...  \n",
       "25684  \"Don‚Äôt be afraid of being unique - it's like b...  \n",
       "25685  \"When the achiever achieves, it's not a platea...  \n",
       "25686  Enter the \"Think Like A Champion\" signed book ...  \n",
       "25687  \"Strive for wholeness and keep your sense of w...  \n",
       "25688  Listen to an interview with Donald Trump discu...  \n",
       "25689  Miss USA Tara Conner will not be fired - \"I've...  \n",
       "25690  \"My persona will never be that of a wallflower...  \n",
       "25691  New Blog Post: Celebrity Apprentice Finale and...  \n",
       "25692  Donald Trump reads Top Ten Financial Tips on L...  \n",
       "25693  Donald Trump will be appearing on The View tom...  \n",
       "25694  Be sure to tune in and watch Donald Trump on L...  \n",
       "\n",
       "[25695 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "input_file = open(\"all_tweets.json\")\n",
    "json_array = json.load(input_file)\n",
    "tweets = pd.DataFrame(json_array, columns=[\"created_at\", \"id_str\", \"text\"])\n",
    "\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Jahr hinzuf√ºgen\n",
    "F√ºr unsere Auswertungen interessiert uns nur das Jahr, in dem der Tweet verfasst wurde, nicht das genaue Datum. Wir f√ºgen daher dem Dataframe eine zus√§tzliche Spalte ```year``` hinzu und verwenden die Pandas-Funktion ```DatetimeIndex```, um aus dem String einen DatetimeIndex zu machen, auf dessen einzelne Felder (```year```, ```month```, ```day```, ...) dann mittels Punktoperator zugegriffen werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun Apr 28 12:59:53 +0000 2019</td>\n",
       "      <td>1122485588580605953</td>\n",
       "      <td>Will be interviewed by @MariaBartiromo on @Fox...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun Apr 28 03:10:25 +0000 2019</td>\n",
       "      <td>1122337243744497664</td>\n",
       "      <td>....for the more traditional, but not very bri...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sun Apr 28 03:10:24 +0000 2019</td>\n",
       "      <td>1122337240330297344</td>\n",
       "      <td>The Democratic National Committee, sometimes r...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Apr 28 02:57:32 +0000 2019</td>\n",
       "      <td>1122334000519868416</td>\n",
       "      <td>....Ever since Andrew came to my office to ask...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun Apr 28 02:57:31 +0000 2019</td>\n",
       "      <td>1122333996451418112</td>\n",
       "      <td>Thank you to brilliant and highly respected at...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sun Apr 28 02:07:11 +0000 2019</td>\n",
       "      <td>1122321330282561536</td>\n",
       "      <td>Thank you Green Bay, Wisconsin! MAKE AMERICA G...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sun Apr 28 01:58:39 +0000 2019</td>\n",
       "      <td>1122319181221892096</td>\n",
       "      <td>Beautiful #TrumpRally tonight in Green Bay, Wi...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sat Apr 27 23:46:06 +0000 2019</td>\n",
       "      <td>1122285823473401857</td>\n",
       "      <td>Just arrived in Green Bay, Wisconsin for a #MA...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sat Apr 27 22:47:01 +0000 2019</td>\n",
       "      <td>1122270956192272385</td>\n",
       "      <td>Sincerest THANK YOU to our great Border Patrol...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sat Apr 27 22:14:25 +0000 2019</td>\n",
       "      <td>1122262750531477504</td>\n",
       "      <td>Great day with Prime Minister @AbeShinzo of Ja...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sat Apr 27 22:00:23 +0000 2019</td>\n",
       "      <td>1122259220215164928</td>\n",
       "      <td>Leaving now for Green Bay, Wisconsin - BIG CRO...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sat Apr 27 21:41:05 +0000 2019</td>\n",
       "      <td>1122254362175332355</td>\n",
       "      <td>Thoughts and prayers to all of those affected ...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sat Apr 27 17:05:36 +0000 2019</td>\n",
       "      <td>1122185034281172994</td>\n",
       "      <td>We must end the Opioid Crisis. Do your part to...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sat Apr 27 16:41:38 +0000 2019</td>\n",
       "      <td>1122179005715820546</td>\n",
       "      <td>We must end the Opioid Crisis. Do your part to...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sat Apr 27 12:06:03 +0000 2019</td>\n",
       "      <td>1122109651087241216</td>\n",
       "      <td>Congratulations to Nick Bosa on being picked n...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fri Apr 26 22:57:34 +0000 2019</td>\n",
       "      <td>1121911223212285953</td>\n",
       "      <td>THANK YOU @NRA! #NRAAM https://t.co/SWkpe1eFhT</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fri Apr 26 19:13:29 +0000 2019</td>\n",
       "      <td>1121854831327621125</td>\n",
       "      <td>‚ÄúU.S. Economy Grows 3.2% in Q1, Smashing Expec...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fri Apr 26 18:31:47 +0000 2019</td>\n",
       "      <td>1121844339200540672</td>\n",
       "      <td>Spoke to Saudi Arabia and others about increas...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fri Apr 26 17:34:33 +0000 2019</td>\n",
       "      <td>1121829933679042565</td>\n",
       "      <td>Great NRA crowd and enthusiasm in Indiana. Tha...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fri Apr 26 14:25:28 +0000 2019</td>\n",
       "      <td>1121782348469522435</td>\n",
       "      <td>Just out: Real GDP for First Quarter grew 3.2%...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Fri Apr 26 12:47:07 +0000 2019</td>\n",
       "      <td>1121757597139439618</td>\n",
       "      <td>Heading to Indianapolis to speak at the big NR...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Fri Apr 26 12:39:55 +0000 2019</td>\n",
       "      <td>1121755785246195712</td>\n",
       "      <td>Weirdo Tom Steyer, who didn‚Äôt have the ‚Äúguts‚Äù ...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Fri Apr 26 11:32:40 +0000 2019</td>\n",
       "      <td>1121738863486095360</td>\n",
       "      <td>‚ÄúPresident Donald J. Trump is the greatest hos...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Fri Apr 26 11:12:21 +0000 2019</td>\n",
       "      <td>1121733749757087750</td>\n",
       "      <td>No money was paid to North Korea for Otto Warm...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Fri Apr 26 00:59:14 +0000 2019</td>\n",
       "      <td>1121579455330254850</td>\n",
       "      <td>I will be interviewed on @seanhannity at 9:00 ...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Thu Apr 25 18:11:16 +0000 2019</td>\n",
       "      <td>1121476784376225798</td>\n",
       "      <td>Thank you! #MAGAüá∫üá∏ https://t.co/EWjwRlmIve</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Thu Apr 25 18:09:25 +0000 2019</td>\n",
       "      <td>1121476321882902529</td>\n",
       "      <td>Our Border Control Agents have done an incredi...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Thu Apr 25 16:32:44 +0000 2019</td>\n",
       "      <td>1121451990712762369</td>\n",
       "      <td>Look forward to seeing everyone in Indianapoli...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Thu Apr 25 14:35:11 +0000 2019</td>\n",
       "      <td>1121422408420855810</td>\n",
       "      <td>I will be interviewed by @seanhannity tonight ...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Thu Apr 25 12:22:18 +0000 2019</td>\n",
       "      <td>1121388967444799488</td>\n",
       "      <td>Welcome to the race Sleepy Joe. I only hope yo...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25665</th>\n",
       "      <td>Wed Jun 24 22:09:19 +0000 2009</td>\n",
       "      <td>2317112756</td>\n",
       "      <td>Donald Trump‚Äôs commercial-free WWE Raw does bi...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25666</th>\n",
       "      <td>Tue Jun 23 13:40:38 +0000 2009</td>\n",
       "      <td>2294519255</td>\n",
       "      <td>‚ÄúExpand your life every day.‚Äù ‚ÄìDonald J. Trump...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25667</th>\n",
       "      <td>Sun Jun 21 14:47:41 +0000 2009</td>\n",
       "      <td>2266041769</td>\n",
       "      <td>- Wishing a Happy Father's Day to all the Dad'...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25668</th>\n",
       "      <td>Thu Jun 18 13:26:53 +0000 2009</td>\n",
       "      <td>2222067805</td>\n",
       "      <td>RE: FB Vanity URLs: SF Chronicle - \"David Beck...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25669</th>\n",
       "      <td>Mon Jun 15 23:13:05 +0000 2009</td>\n",
       "      <td>2184650461</td>\n",
       "      <td>Thanks to all for your thoughtful birthday wis...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25670</th>\n",
       "      <td>Sun Jun 14 14:25:36 +0000 2009</td>\n",
       "      <td>2165353946</td>\n",
       "      <td>Today is Donald Trump's Birthday! Send him you...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25671</th>\n",
       "      <td>Mon Jun 08 20:15:29 +0000 2009</td>\n",
       "      <td>2080633709</td>\n",
       "      <td>Last week to enter the \"Think Like A Champion\"...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25672</th>\n",
       "      <td>Fri Jun 05 18:21:37 +0000 2009</td>\n",
       "      <td>2045871770</td>\n",
       "      <td>‚ÄúIf you don't have problems, you're pretending...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25673</th>\n",
       "      <td>Wed Jun 03 18:19:49 +0000 2009</td>\n",
       "      <td>2019316195</td>\n",
       "      <td>Check out Donald Trump's new iGoogle Showcase ...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25674</th>\n",
       "      <td>Thu May 28 18:03:34 +0000 2009</td>\n",
       "      <td>1949899014</td>\n",
       "      <td>\"You have to know when to call it quits and wh...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25675</th>\n",
       "      <td>Wed May 27 14:18:52 +0000 2009</td>\n",
       "      <td>1936022874</td>\n",
       "      <td>Read an excerpt from Think Like A Champion by ...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25676</th>\n",
       "      <td>Tue May 26 14:42:01 +0000 2009</td>\n",
       "      <td>1924074459</td>\n",
       "      <td>\"Your higher self is in direct opposition to y...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25677</th>\n",
       "      <td>Sat May 23 16:11:19 +0000 2009</td>\n",
       "      <td>1894284587</td>\n",
       "      <td>Did you know Donald Trump is on Facebook? http...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25678</th>\n",
       "      <td>Fri May 22 16:28:34 +0000 2009</td>\n",
       "      <td>1884022748</td>\n",
       "      <td>Don't forget to enter the \"Think Like A Champi...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25679</th>\n",
       "      <td>Fri May 22 02:59:39 +0000 2009</td>\n",
       "      <td>1878373267</td>\n",
       "      <td>\"Keep it fast, short and direct - whatever it ...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25680</th>\n",
       "      <td>Wed May 20 22:29:47 +0000 2009</td>\n",
       "      <td>1864367186</td>\n",
       "      <td>Read a great interview with Donald Trump that ...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25681</th>\n",
       "      <td>Wed May 20 13:25:39 +0000 2009</td>\n",
       "      <td>1859044981</td>\n",
       "      <td>\"Always know you could be on the precipice of ...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25682</th>\n",
       "      <td>Tue May 19 17:43:39 +0000 2009</td>\n",
       "      <td>1849558306</td>\n",
       "      <td>\"...these days...we could all use a little of ...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25683</th>\n",
       "      <td>Mon May 18 14:26:00 +0000 2009</td>\n",
       "      <td>1836131903</td>\n",
       "      <td>\"We win in our lives by having a champion's vi...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25684</th>\n",
       "      <td>Sun May 17 15:00:03 +0000 2009</td>\n",
       "      <td>1826225450</td>\n",
       "      <td>\"Don‚Äôt be afraid of being unique - it's like b...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25685</th>\n",
       "      <td>Sat May 16 22:22:45 +0000 2009</td>\n",
       "      <td>1820624395</td>\n",
       "      <td>\"When the achiever achieves, it's not a platea...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25686</th>\n",
       "      <td>Fri May 15 14:13:13 +0000 2009</td>\n",
       "      <td>1806258917</td>\n",
       "      <td>Enter the \"Think Like A Champion\" signed book ...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25687</th>\n",
       "      <td>Thu May 14 16:30:40 +0000 2009</td>\n",
       "      <td>1796477499</td>\n",
       "      <td>\"Strive for wholeness and keep your sense of w...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25688</th>\n",
       "      <td>Wed May 13 17:38:28 +0000 2009</td>\n",
       "      <td>1786560616</td>\n",
       "      <td>Listen to an interview with Donald Trump discu...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25689</th>\n",
       "      <td>Tue May 12 19:21:55 +0000 2009</td>\n",
       "      <td>1776419923</td>\n",
       "      <td>Miss USA Tara Conner will not be fired - \"I've...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25690</th>\n",
       "      <td>Tue May 12 14:07:28 +0000 2009</td>\n",
       "      <td>1773561338</td>\n",
       "      <td>\"My persona will never be that of a wallflower...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25691</th>\n",
       "      <td>Fri May 08 20:40:15 +0000 2009</td>\n",
       "      <td>1741160716</td>\n",
       "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25692</th>\n",
       "      <td>Fri May 08 13:38:08 +0000 2009</td>\n",
       "      <td>1737479987</td>\n",
       "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25693</th>\n",
       "      <td>Tue May 05 01:00:10 +0000 2009</td>\n",
       "      <td>1701461182</td>\n",
       "      <td>Donald Trump will be appearing on The View tom...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25694</th>\n",
       "      <td>Mon May 04 18:54:25 +0000 2009</td>\n",
       "      <td>1698308935</td>\n",
       "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25695 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           created_at               id_str  \\\n",
       "0      Sun Apr 28 12:59:53 +0000 2019  1122485588580605953   \n",
       "1      Sun Apr 28 03:10:25 +0000 2019  1122337243744497664   \n",
       "2      Sun Apr 28 03:10:24 +0000 2019  1122337240330297344   \n",
       "3      Sun Apr 28 02:57:32 +0000 2019  1122334000519868416   \n",
       "4      Sun Apr 28 02:57:31 +0000 2019  1122333996451418112   \n",
       "5      Sun Apr 28 02:07:11 +0000 2019  1122321330282561536   \n",
       "6      Sun Apr 28 01:58:39 +0000 2019  1122319181221892096   \n",
       "7      Sat Apr 27 23:46:06 +0000 2019  1122285823473401857   \n",
       "8      Sat Apr 27 22:47:01 +0000 2019  1122270956192272385   \n",
       "9      Sat Apr 27 22:14:25 +0000 2019  1122262750531477504   \n",
       "10     Sat Apr 27 22:00:23 +0000 2019  1122259220215164928   \n",
       "11     Sat Apr 27 21:41:05 +0000 2019  1122254362175332355   \n",
       "12     Sat Apr 27 17:05:36 +0000 2019  1122185034281172994   \n",
       "13     Sat Apr 27 16:41:38 +0000 2019  1122179005715820546   \n",
       "14     Sat Apr 27 12:06:03 +0000 2019  1122109651087241216   \n",
       "15     Fri Apr 26 22:57:34 +0000 2019  1121911223212285953   \n",
       "16     Fri Apr 26 19:13:29 +0000 2019  1121854831327621125   \n",
       "17     Fri Apr 26 18:31:47 +0000 2019  1121844339200540672   \n",
       "18     Fri Apr 26 17:34:33 +0000 2019  1121829933679042565   \n",
       "19     Fri Apr 26 14:25:28 +0000 2019  1121782348469522435   \n",
       "20     Fri Apr 26 12:47:07 +0000 2019  1121757597139439618   \n",
       "21     Fri Apr 26 12:39:55 +0000 2019  1121755785246195712   \n",
       "22     Fri Apr 26 11:32:40 +0000 2019  1121738863486095360   \n",
       "23     Fri Apr 26 11:12:21 +0000 2019  1121733749757087750   \n",
       "24     Fri Apr 26 00:59:14 +0000 2019  1121579455330254850   \n",
       "25     Thu Apr 25 18:11:16 +0000 2019  1121476784376225798   \n",
       "26     Thu Apr 25 18:09:25 +0000 2019  1121476321882902529   \n",
       "27     Thu Apr 25 16:32:44 +0000 2019  1121451990712762369   \n",
       "28     Thu Apr 25 14:35:11 +0000 2019  1121422408420855810   \n",
       "29     Thu Apr 25 12:22:18 +0000 2019  1121388967444799488   \n",
       "...                               ...                  ...   \n",
       "25665  Wed Jun 24 22:09:19 +0000 2009           2317112756   \n",
       "25666  Tue Jun 23 13:40:38 +0000 2009           2294519255   \n",
       "25667  Sun Jun 21 14:47:41 +0000 2009           2266041769   \n",
       "25668  Thu Jun 18 13:26:53 +0000 2009           2222067805   \n",
       "25669  Mon Jun 15 23:13:05 +0000 2009           2184650461   \n",
       "25670  Sun Jun 14 14:25:36 +0000 2009           2165353946   \n",
       "25671  Mon Jun 08 20:15:29 +0000 2009           2080633709   \n",
       "25672  Fri Jun 05 18:21:37 +0000 2009           2045871770   \n",
       "25673  Wed Jun 03 18:19:49 +0000 2009           2019316195   \n",
       "25674  Thu May 28 18:03:34 +0000 2009           1949899014   \n",
       "25675  Wed May 27 14:18:52 +0000 2009           1936022874   \n",
       "25676  Tue May 26 14:42:01 +0000 2009           1924074459   \n",
       "25677  Sat May 23 16:11:19 +0000 2009           1894284587   \n",
       "25678  Fri May 22 16:28:34 +0000 2009           1884022748   \n",
       "25679  Fri May 22 02:59:39 +0000 2009           1878373267   \n",
       "25680  Wed May 20 22:29:47 +0000 2009           1864367186   \n",
       "25681  Wed May 20 13:25:39 +0000 2009           1859044981   \n",
       "25682  Tue May 19 17:43:39 +0000 2009           1849558306   \n",
       "25683  Mon May 18 14:26:00 +0000 2009           1836131903   \n",
       "25684  Sun May 17 15:00:03 +0000 2009           1826225450   \n",
       "25685  Sat May 16 22:22:45 +0000 2009           1820624395   \n",
       "25686  Fri May 15 14:13:13 +0000 2009           1806258917   \n",
       "25687  Thu May 14 16:30:40 +0000 2009           1796477499   \n",
       "25688  Wed May 13 17:38:28 +0000 2009           1786560616   \n",
       "25689  Tue May 12 19:21:55 +0000 2009           1776419923   \n",
       "25690  Tue May 12 14:07:28 +0000 2009           1773561338   \n",
       "25691  Fri May 08 20:40:15 +0000 2009           1741160716   \n",
       "25692  Fri May 08 13:38:08 +0000 2009           1737479987   \n",
       "25693  Tue May 05 01:00:10 +0000 2009           1701461182   \n",
       "25694  Mon May 04 18:54:25 +0000 2009           1698308935   \n",
       "\n",
       "                                                    text  year  \n",
       "0      Will be interviewed by @MariaBartiromo on @Fox...  2019  \n",
       "1      ....for the more traditional, but not very bri...  2019  \n",
       "2      The Democratic National Committee, sometimes r...  2019  \n",
       "3      ....Ever since Andrew came to my office to ask...  2019  \n",
       "4      Thank you to brilliant and highly respected at...  2019  \n",
       "5      Thank you Green Bay, Wisconsin! MAKE AMERICA G...  2019  \n",
       "6      Beautiful #TrumpRally tonight in Green Bay, Wi...  2019  \n",
       "7      Just arrived in Green Bay, Wisconsin for a #MA...  2019  \n",
       "8      Sincerest THANK YOU to our great Border Patrol...  2019  \n",
       "9      Great day with Prime Minister @AbeShinzo of Ja...  2019  \n",
       "10     Leaving now for Green Bay, Wisconsin - BIG CRO...  2019  \n",
       "11     Thoughts and prayers to all of those affected ...  2019  \n",
       "12     We must end the Opioid Crisis. Do your part to...  2019  \n",
       "13     We must end the Opioid Crisis. Do your part to...  2019  \n",
       "14     Congratulations to Nick Bosa on being picked n...  2019  \n",
       "15        THANK YOU @NRA! #NRAAM https://t.co/SWkpe1eFhT  2019  \n",
       "16     ‚ÄúU.S. Economy Grows 3.2% in Q1, Smashing Expec...  2019  \n",
       "17     Spoke to Saudi Arabia and others about increas...  2019  \n",
       "18     Great NRA crowd and enthusiasm in Indiana. Tha...  2019  \n",
       "19     Just out: Real GDP for First Quarter grew 3.2%...  2019  \n",
       "20     Heading to Indianapolis to speak at the big NR...  2019  \n",
       "21     Weirdo Tom Steyer, who didn‚Äôt have the ‚Äúguts‚Äù ...  2019  \n",
       "22     ‚ÄúPresident Donald J. Trump is the greatest hos...  2019  \n",
       "23     No money was paid to North Korea for Otto Warm...  2019  \n",
       "24     I will be interviewed on @seanhannity at 9:00 ...  2019  \n",
       "25            Thank you! #MAGAüá∫üá∏ https://t.co/EWjwRlmIve  2019  \n",
       "26     Our Border Control Agents have done an incredi...  2019  \n",
       "27     Look forward to seeing everyone in Indianapoli...  2019  \n",
       "28     I will be interviewed by @seanhannity tonight ...  2019  \n",
       "29     Welcome to the race Sleepy Joe. I only hope yo...  2019  \n",
       "...                                                  ...   ...  \n",
       "25665  Donald Trump‚Äôs commercial-free WWE Raw does bi...  2009  \n",
       "25666  ‚ÄúExpand your life every day.‚Äù ‚ÄìDonald J. Trump...  2009  \n",
       "25667  - Wishing a Happy Father's Day to all the Dad'...  2009  \n",
       "25668  RE: FB Vanity URLs: SF Chronicle - \"David Beck...  2009  \n",
       "25669  Thanks to all for your thoughtful birthday wis...  2009  \n",
       "25670  Today is Donald Trump's Birthday! Send him you...  2009  \n",
       "25671  Last week to enter the \"Think Like A Champion\"...  2009  \n",
       "25672  ‚ÄúIf you don't have problems, you're pretending...  2009  \n",
       "25673  Check out Donald Trump's new iGoogle Showcase ...  2009  \n",
       "25674  \"You have to know when to call it quits and wh...  2009  \n",
       "25675  Read an excerpt from Think Like A Champion by ...  2009  \n",
       "25676  \"Your higher self is in direct opposition to y...  2009  \n",
       "25677  Did you know Donald Trump is on Facebook? http...  2009  \n",
       "25678  Don't forget to enter the \"Think Like A Champi...  2009  \n",
       "25679  \"Keep it fast, short and direct - whatever it ...  2009  \n",
       "25680  Read a great interview with Donald Trump that ...  2009  \n",
       "25681  \"Always know you could be on the precipice of ...  2009  \n",
       "25682  \"...these days...we could all use a little of ...  2009  \n",
       "25683  \"We win in our lives by having a champion's vi...  2009  \n",
       "25684  \"Don‚Äôt be afraid of being unique - it's like b...  2009  \n",
       "25685  \"When the achiever achieves, it's not a platea...  2009  \n",
       "25686  Enter the \"Think Like A Champion\" signed book ...  2009  \n",
       "25687  \"Strive for wholeness and keep your sense of w...  2009  \n",
       "25688  Listen to an interview with Donald Trump discu...  2009  \n",
       "25689  Miss USA Tara Conner will not be fired - \"I've...  2009  \n",
       "25690  \"My persona will never be that of a wallflower...  2009  \n",
       "25691  New Blog Post: Celebrity Apprentice Finale and...  2009  \n",
       "25692  Donald Trump reads Top Ten Financial Tips on L...  2009  \n",
       "25693  Donald Trump will be appearing on The View tom...  2009  \n",
       "25694  Be sure to tune in and watch Donald Trump on L...  2009  \n",
       "\n",
       "[25695 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['year'] = pd.DatetimeIndex(tweets['created_at']).year\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Textl√§nge analysieren\n",
    "Naturgem√§√ü gibt es bei Tweets nur eine begrenzte Varianz, was die Textl√§nge angeht. Wir wollen uns dennoch anschauen, wie sich die Textl√§nge im Laufe der Jahre entwickelt hat.\n",
    "Dazu f√ºgen wir unserem Dataframe zun√§chst eine Spalte ```text_length``` hinzu, in der wir festhalten, welche L√§nge der jeweilige Tweet-Text hat.\n",
    "\n",
    "**Hinweis**\n",
    "Mittels ```apply``` lassen sich Funktionen auf Spalten des Dataframes mappen: ```df['new'] = df['old'].apply(lambda x : fancy_stuff(x))```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun Apr 28 12:59:53 +0000 2019</td>\n",
       "      <td>1122485588580605953</td>\n",
       "      <td>Will be interviewed by @MariaBartiromo on @Fox...</td>\n",
       "      <td>2019</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun Apr 28 03:10:25 +0000 2019</td>\n",
       "      <td>1122337243744497664</td>\n",
       "      <td>....for the more traditional, but not very bri...</td>\n",
       "      <td>2019</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sun Apr 28 03:10:24 +0000 2019</td>\n",
       "      <td>1122337240330297344</td>\n",
       "      <td>The Democratic National Committee, sometimes r...</td>\n",
       "      <td>2019</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Apr 28 02:57:32 +0000 2019</td>\n",
       "      <td>1122334000519868416</td>\n",
       "      <td>....Ever since Andrew came to my office to ask...</td>\n",
       "      <td>2019</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun Apr 28 02:57:31 +0000 2019</td>\n",
       "      <td>1122333996451418112</td>\n",
       "      <td>Thank you to brilliant and highly respected at...</td>\n",
       "      <td>2019</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sun Apr 28 02:07:11 +0000 2019</td>\n",
       "      <td>1122321330282561536</td>\n",
       "      <td>Thank you Green Bay, Wisconsin! MAKE AMERICA G...</td>\n",
       "      <td>2019</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sun Apr 28 01:58:39 +0000 2019</td>\n",
       "      <td>1122319181221892096</td>\n",
       "      <td>Beautiful #TrumpRally tonight in Green Bay, Wi...</td>\n",
       "      <td>2019</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sat Apr 27 23:46:06 +0000 2019</td>\n",
       "      <td>1122285823473401857</td>\n",
       "      <td>Just arrived in Green Bay, Wisconsin for a #MA...</td>\n",
       "      <td>2019</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sat Apr 27 22:47:01 +0000 2019</td>\n",
       "      <td>1122270956192272385</td>\n",
       "      <td>Sincerest THANK YOU to our great Border Patrol...</td>\n",
       "      <td>2019</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sat Apr 27 22:14:25 +0000 2019</td>\n",
       "      <td>1122262750531477504</td>\n",
       "      <td>Great day with Prime Minister @AbeShinzo of Ja...</td>\n",
       "      <td>2019</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sat Apr 27 22:00:23 +0000 2019</td>\n",
       "      <td>1122259220215164928</td>\n",
       "      <td>Leaving now for Green Bay, Wisconsin - BIG CRO...</td>\n",
       "      <td>2019</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sat Apr 27 21:41:05 +0000 2019</td>\n",
       "      <td>1122254362175332355</td>\n",
       "      <td>Thoughts and prayers to all of those affected ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sat Apr 27 17:05:36 +0000 2019</td>\n",
       "      <td>1122185034281172994</td>\n",
       "      <td>We must end the Opioid Crisis. Do your part to...</td>\n",
       "      <td>2019</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sat Apr 27 16:41:38 +0000 2019</td>\n",
       "      <td>1122179005715820546</td>\n",
       "      <td>We must end the Opioid Crisis. Do your part to...</td>\n",
       "      <td>2019</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sat Apr 27 12:06:03 +0000 2019</td>\n",
       "      <td>1122109651087241216</td>\n",
       "      <td>Congratulations to Nick Bosa on being picked n...</td>\n",
       "      <td>2019</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fri Apr 26 22:57:34 +0000 2019</td>\n",
       "      <td>1121911223212285953</td>\n",
       "      <td>THANK YOU @NRA! #NRAAM https://t.co/SWkpe1eFhT</td>\n",
       "      <td>2019</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fri Apr 26 19:13:29 +0000 2019</td>\n",
       "      <td>1121854831327621125</td>\n",
       "      <td>‚ÄúU.S. Economy Grows 3.2% in Q1, Smashing Expec...</td>\n",
       "      <td>2019</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fri Apr 26 18:31:47 +0000 2019</td>\n",
       "      <td>1121844339200540672</td>\n",
       "      <td>Spoke to Saudi Arabia and others about increas...</td>\n",
       "      <td>2019</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fri Apr 26 17:34:33 +0000 2019</td>\n",
       "      <td>1121829933679042565</td>\n",
       "      <td>Great NRA crowd and enthusiasm in Indiana. Tha...</td>\n",
       "      <td>2019</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fri Apr 26 14:25:28 +0000 2019</td>\n",
       "      <td>1121782348469522435</td>\n",
       "      <td>Just out: Real GDP for First Quarter grew 3.2%...</td>\n",
       "      <td>2019</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Fri Apr 26 12:47:07 +0000 2019</td>\n",
       "      <td>1121757597139439618</td>\n",
       "      <td>Heading to Indianapolis to speak at the big NR...</td>\n",
       "      <td>2019</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Fri Apr 26 12:39:55 +0000 2019</td>\n",
       "      <td>1121755785246195712</td>\n",
       "      <td>Weirdo Tom Steyer, who didn‚Äôt have the ‚Äúguts‚Äù ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Fri Apr 26 11:32:40 +0000 2019</td>\n",
       "      <td>1121738863486095360</td>\n",
       "      <td>‚ÄúPresident Donald J. Trump is the greatest hos...</td>\n",
       "      <td>2019</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Fri Apr 26 11:12:21 +0000 2019</td>\n",
       "      <td>1121733749757087750</td>\n",
       "      <td>No money was paid to North Korea for Otto Warm...</td>\n",
       "      <td>2019</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Fri Apr 26 00:59:14 +0000 2019</td>\n",
       "      <td>1121579455330254850</td>\n",
       "      <td>I will be interviewed on @seanhannity at 9:00 ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Thu Apr 25 18:11:16 +0000 2019</td>\n",
       "      <td>1121476784376225798</td>\n",
       "      <td>Thank you! #MAGAüá∫üá∏ https://t.co/EWjwRlmIve</td>\n",
       "      <td>2019</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Thu Apr 25 18:09:25 +0000 2019</td>\n",
       "      <td>1121476321882902529</td>\n",
       "      <td>Our Border Control Agents have done an incredi...</td>\n",
       "      <td>2019</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Thu Apr 25 16:32:44 +0000 2019</td>\n",
       "      <td>1121451990712762369</td>\n",
       "      <td>Look forward to seeing everyone in Indianapoli...</td>\n",
       "      <td>2019</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Thu Apr 25 14:35:11 +0000 2019</td>\n",
       "      <td>1121422408420855810</td>\n",
       "      <td>I will be interviewed by @seanhannity tonight ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Thu Apr 25 12:22:18 +0000 2019</td>\n",
       "      <td>1121388967444799488</td>\n",
       "      <td>Welcome to the race Sleepy Joe. I only hope yo...</td>\n",
       "      <td>2019</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25665</th>\n",
       "      <td>Wed Jun 24 22:09:19 +0000 2009</td>\n",
       "      <td>2317112756</td>\n",
       "      <td>Donald Trump‚Äôs commercial-free WWE Raw does bi...</td>\n",
       "      <td>2009</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25666</th>\n",
       "      <td>Tue Jun 23 13:40:38 +0000 2009</td>\n",
       "      <td>2294519255</td>\n",
       "      <td>‚ÄúExpand your life every day.‚Äù ‚ÄìDonald J. Trump...</td>\n",
       "      <td>2009</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25667</th>\n",
       "      <td>Sun Jun 21 14:47:41 +0000 2009</td>\n",
       "      <td>2266041769</td>\n",
       "      <td>- Wishing a Happy Father's Day to all the Dad'...</td>\n",
       "      <td>2009</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25668</th>\n",
       "      <td>Thu Jun 18 13:26:53 +0000 2009</td>\n",
       "      <td>2222067805</td>\n",
       "      <td>RE: FB Vanity URLs: SF Chronicle - \"David Beck...</td>\n",
       "      <td>2009</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25669</th>\n",
       "      <td>Mon Jun 15 23:13:05 +0000 2009</td>\n",
       "      <td>2184650461</td>\n",
       "      <td>Thanks to all for your thoughtful birthday wis...</td>\n",
       "      <td>2009</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25670</th>\n",
       "      <td>Sun Jun 14 14:25:36 +0000 2009</td>\n",
       "      <td>2165353946</td>\n",
       "      <td>Today is Donald Trump's Birthday! Send him you...</td>\n",
       "      <td>2009</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25671</th>\n",
       "      <td>Mon Jun 08 20:15:29 +0000 2009</td>\n",
       "      <td>2080633709</td>\n",
       "      <td>Last week to enter the \"Think Like A Champion\"...</td>\n",
       "      <td>2009</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25672</th>\n",
       "      <td>Fri Jun 05 18:21:37 +0000 2009</td>\n",
       "      <td>2045871770</td>\n",
       "      <td>‚ÄúIf you don't have problems, you're pretending...</td>\n",
       "      <td>2009</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25673</th>\n",
       "      <td>Wed Jun 03 18:19:49 +0000 2009</td>\n",
       "      <td>2019316195</td>\n",
       "      <td>Check out Donald Trump's new iGoogle Showcase ...</td>\n",
       "      <td>2009</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25674</th>\n",
       "      <td>Thu May 28 18:03:34 +0000 2009</td>\n",
       "      <td>1949899014</td>\n",
       "      <td>\"You have to know when to call it quits and wh...</td>\n",
       "      <td>2009</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25675</th>\n",
       "      <td>Wed May 27 14:18:52 +0000 2009</td>\n",
       "      <td>1936022874</td>\n",
       "      <td>Read an excerpt from Think Like A Champion by ...</td>\n",
       "      <td>2009</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25676</th>\n",
       "      <td>Tue May 26 14:42:01 +0000 2009</td>\n",
       "      <td>1924074459</td>\n",
       "      <td>\"Your higher self is in direct opposition to y...</td>\n",
       "      <td>2009</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25677</th>\n",
       "      <td>Sat May 23 16:11:19 +0000 2009</td>\n",
       "      <td>1894284587</td>\n",
       "      <td>Did you know Donald Trump is on Facebook? http...</td>\n",
       "      <td>2009</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25678</th>\n",
       "      <td>Fri May 22 16:28:34 +0000 2009</td>\n",
       "      <td>1884022748</td>\n",
       "      <td>Don't forget to enter the \"Think Like A Champi...</td>\n",
       "      <td>2009</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25679</th>\n",
       "      <td>Fri May 22 02:59:39 +0000 2009</td>\n",
       "      <td>1878373267</td>\n",
       "      <td>\"Keep it fast, short and direct - whatever it ...</td>\n",
       "      <td>2009</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25680</th>\n",
       "      <td>Wed May 20 22:29:47 +0000 2009</td>\n",
       "      <td>1864367186</td>\n",
       "      <td>Read a great interview with Donald Trump that ...</td>\n",
       "      <td>2009</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25681</th>\n",
       "      <td>Wed May 20 13:25:39 +0000 2009</td>\n",
       "      <td>1859044981</td>\n",
       "      <td>\"Always know you could be on the precipice of ...</td>\n",
       "      <td>2009</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25682</th>\n",
       "      <td>Tue May 19 17:43:39 +0000 2009</td>\n",
       "      <td>1849558306</td>\n",
       "      <td>\"...these days...we could all use a little of ...</td>\n",
       "      <td>2009</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25683</th>\n",
       "      <td>Mon May 18 14:26:00 +0000 2009</td>\n",
       "      <td>1836131903</td>\n",
       "      <td>\"We win in our lives by having a champion's vi...</td>\n",
       "      <td>2009</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25684</th>\n",
       "      <td>Sun May 17 15:00:03 +0000 2009</td>\n",
       "      <td>1826225450</td>\n",
       "      <td>\"Don‚Äôt be afraid of being unique - it's like b...</td>\n",
       "      <td>2009</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25685</th>\n",
       "      <td>Sat May 16 22:22:45 +0000 2009</td>\n",
       "      <td>1820624395</td>\n",
       "      <td>\"When the achiever achieves, it's not a platea...</td>\n",
       "      <td>2009</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25686</th>\n",
       "      <td>Fri May 15 14:13:13 +0000 2009</td>\n",
       "      <td>1806258917</td>\n",
       "      <td>Enter the \"Think Like A Champion\" signed book ...</td>\n",
       "      <td>2009</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25687</th>\n",
       "      <td>Thu May 14 16:30:40 +0000 2009</td>\n",
       "      <td>1796477499</td>\n",
       "      <td>\"Strive for wholeness and keep your sense of w...</td>\n",
       "      <td>2009</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25688</th>\n",
       "      <td>Wed May 13 17:38:28 +0000 2009</td>\n",
       "      <td>1786560616</td>\n",
       "      <td>Listen to an interview with Donald Trump discu...</td>\n",
       "      <td>2009</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25689</th>\n",
       "      <td>Tue May 12 19:21:55 +0000 2009</td>\n",
       "      <td>1776419923</td>\n",
       "      <td>Miss USA Tara Conner will not be fired - \"I've...</td>\n",
       "      <td>2009</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25690</th>\n",
       "      <td>Tue May 12 14:07:28 +0000 2009</td>\n",
       "      <td>1773561338</td>\n",
       "      <td>\"My persona will never be that of a wallflower...</td>\n",
       "      <td>2009</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25691</th>\n",
       "      <td>Fri May 08 20:40:15 +0000 2009</td>\n",
       "      <td>1741160716</td>\n",
       "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
       "      <td>2009</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25692</th>\n",
       "      <td>Fri May 08 13:38:08 +0000 2009</td>\n",
       "      <td>1737479987</td>\n",
       "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
       "      <td>2009</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25693</th>\n",
       "      <td>Tue May 05 01:00:10 +0000 2009</td>\n",
       "      <td>1701461182</td>\n",
       "      <td>Donald Trump will be appearing on The View tom...</td>\n",
       "      <td>2009</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25694</th>\n",
       "      <td>Mon May 04 18:54:25 +0000 2009</td>\n",
       "      <td>1698308935</td>\n",
       "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
       "      <td>2009</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25695 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           created_at               id_str  \\\n",
       "0      Sun Apr 28 12:59:53 +0000 2019  1122485588580605953   \n",
       "1      Sun Apr 28 03:10:25 +0000 2019  1122337243744497664   \n",
       "2      Sun Apr 28 03:10:24 +0000 2019  1122337240330297344   \n",
       "3      Sun Apr 28 02:57:32 +0000 2019  1122334000519868416   \n",
       "4      Sun Apr 28 02:57:31 +0000 2019  1122333996451418112   \n",
       "5      Sun Apr 28 02:07:11 +0000 2019  1122321330282561536   \n",
       "6      Sun Apr 28 01:58:39 +0000 2019  1122319181221892096   \n",
       "7      Sat Apr 27 23:46:06 +0000 2019  1122285823473401857   \n",
       "8      Sat Apr 27 22:47:01 +0000 2019  1122270956192272385   \n",
       "9      Sat Apr 27 22:14:25 +0000 2019  1122262750531477504   \n",
       "10     Sat Apr 27 22:00:23 +0000 2019  1122259220215164928   \n",
       "11     Sat Apr 27 21:41:05 +0000 2019  1122254362175332355   \n",
       "12     Sat Apr 27 17:05:36 +0000 2019  1122185034281172994   \n",
       "13     Sat Apr 27 16:41:38 +0000 2019  1122179005715820546   \n",
       "14     Sat Apr 27 12:06:03 +0000 2019  1122109651087241216   \n",
       "15     Fri Apr 26 22:57:34 +0000 2019  1121911223212285953   \n",
       "16     Fri Apr 26 19:13:29 +0000 2019  1121854831327621125   \n",
       "17     Fri Apr 26 18:31:47 +0000 2019  1121844339200540672   \n",
       "18     Fri Apr 26 17:34:33 +0000 2019  1121829933679042565   \n",
       "19     Fri Apr 26 14:25:28 +0000 2019  1121782348469522435   \n",
       "20     Fri Apr 26 12:47:07 +0000 2019  1121757597139439618   \n",
       "21     Fri Apr 26 12:39:55 +0000 2019  1121755785246195712   \n",
       "22     Fri Apr 26 11:32:40 +0000 2019  1121738863486095360   \n",
       "23     Fri Apr 26 11:12:21 +0000 2019  1121733749757087750   \n",
       "24     Fri Apr 26 00:59:14 +0000 2019  1121579455330254850   \n",
       "25     Thu Apr 25 18:11:16 +0000 2019  1121476784376225798   \n",
       "26     Thu Apr 25 18:09:25 +0000 2019  1121476321882902529   \n",
       "27     Thu Apr 25 16:32:44 +0000 2019  1121451990712762369   \n",
       "28     Thu Apr 25 14:35:11 +0000 2019  1121422408420855810   \n",
       "29     Thu Apr 25 12:22:18 +0000 2019  1121388967444799488   \n",
       "...                               ...                  ...   \n",
       "25665  Wed Jun 24 22:09:19 +0000 2009           2317112756   \n",
       "25666  Tue Jun 23 13:40:38 +0000 2009           2294519255   \n",
       "25667  Sun Jun 21 14:47:41 +0000 2009           2266041769   \n",
       "25668  Thu Jun 18 13:26:53 +0000 2009           2222067805   \n",
       "25669  Mon Jun 15 23:13:05 +0000 2009           2184650461   \n",
       "25670  Sun Jun 14 14:25:36 +0000 2009           2165353946   \n",
       "25671  Mon Jun 08 20:15:29 +0000 2009           2080633709   \n",
       "25672  Fri Jun 05 18:21:37 +0000 2009           2045871770   \n",
       "25673  Wed Jun 03 18:19:49 +0000 2009           2019316195   \n",
       "25674  Thu May 28 18:03:34 +0000 2009           1949899014   \n",
       "25675  Wed May 27 14:18:52 +0000 2009           1936022874   \n",
       "25676  Tue May 26 14:42:01 +0000 2009           1924074459   \n",
       "25677  Sat May 23 16:11:19 +0000 2009           1894284587   \n",
       "25678  Fri May 22 16:28:34 +0000 2009           1884022748   \n",
       "25679  Fri May 22 02:59:39 +0000 2009           1878373267   \n",
       "25680  Wed May 20 22:29:47 +0000 2009           1864367186   \n",
       "25681  Wed May 20 13:25:39 +0000 2009           1859044981   \n",
       "25682  Tue May 19 17:43:39 +0000 2009           1849558306   \n",
       "25683  Mon May 18 14:26:00 +0000 2009           1836131903   \n",
       "25684  Sun May 17 15:00:03 +0000 2009           1826225450   \n",
       "25685  Sat May 16 22:22:45 +0000 2009           1820624395   \n",
       "25686  Fri May 15 14:13:13 +0000 2009           1806258917   \n",
       "25687  Thu May 14 16:30:40 +0000 2009           1796477499   \n",
       "25688  Wed May 13 17:38:28 +0000 2009           1786560616   \n",
       "25689  Tue May 12 19:21:55 +0000 2009           1776419923   \n",
       "25690  Tue May 12 14:07:28 +0000 2009           1773561338   \n",
       "25691  Fri May 08 20:40:15 +0000 2009           1741160716   \n",
       "25692  Fri May 08 13:38:08 +0000 2009           1737479987   \n",
       "25693  Tue May 05 01:00:10 +0000 2009           1701461182   \n",
       "25694  Mon May 04 18:54:25 +0000 2009           1698308935   \n",
       "\n",
       "                                                    text  year  text_length  \n",
       "0      Will be interviewed by @MariaBartiromo on @Fox...  2019          191  \n",
       "1      ....for the more traditional, but not very bri...  2019          177  \n",
       "2      The Democratic National Committee, sometimes r...  2019          144  \n",
       "3      ....Ever since Andrew came to my office to ask...  2019          214  \n",
       "4      Thank you to brilliant and highly respected at...  2019          145  \n",
       "5      Thank you Green Bay, Wisconsin! MAKE AMERICA G...  2019           82  \n",
       "6      Beautiful #TrumpRally tonight in Green Bay, Wi...  2019          144  \n",
       "7      Just arrived in Green Bay, Wisconsin for a #MA...  2019          116  \n",
       "8      Sincerest THANK YOU to our great Border Patrol...  2019          186  \n",
       "9      Great day with Prime Minister @AbeShinzo of Ja...  2019          283  \n",
       "10     Leaving now for Green Bay, Wisconsin - BIG CRO...  2019           78  \n",
       "11     Thoughts and prayers to all of those affected ...  2019          188  \n",
       "12     We must end the Opioid Crisis. Do your part to...  2019          192  \n",
       "13     We must end the Opioid Crisis. Do your part to...  2019          192  \n",
       "14     Congratulations to Nick Bosa on being picked n...  2019          263  \n",
       "15        THANK YOU @NRA! #NRAAM https://t.co/SWkpe1eFhT  2019           46  \n",
       "16     ‚ÄúU.S. Economy Grows 3.2% in Q1, Smashing Expec...  2019           78  \n",
       "17     Spoke to Saudi Arabia and others about increas...  2019          276  \n",
       "18     Great NRA crowd and enthusiasm in Indiana. Tha...  2019           98  \n",
       "19     Just out: Real GDP for First Quarter grew 3.2%...  2019          171  \n",
       "20     Heading to Indianapolis to speak at the big NR...  2019          229  \n",
       "21     Weirdo Tom Steyer, who didn‚Äôt have the ‚Äúguts‚Äù ...  2019          283  \n",
       "22     ‚ÄúPresident Donald J. Trump is the greatest hos...  2019          249  \n",
       "23     No money was paid to North Korea for Otto Warm...  2019          275  \n",
       "24     I will be interviewed on @seanhannity at 9:00 ...  2019           72  \n",
       "25            Thank you! #MAGAüá∫üá∏ https://t.co/EWjwRlmIve  2019           42  \n",
       "26     Our Border Control Agents have done an incredi...  2019          260  \n",
       "27     Look forward to seeing everyone in Indianapoli...  2019           90  \n",
       "28     I will be interviewed by @seanhannity tonight ...  2019           76  \n",
       "29     Welcome to the race Sleepy Joe. I only hope yo...  2019          284  \n",
       "...                                                  ...   ...          ...  \n",
       "25665  Donald Trump‚Äôs commercial-free WWE Raw does bi...  2009           81  \n",
       "25666  ‚ÄúExpand your life every day.‚Äù ‚ÄìDonald J. Trump...  2009           72  \n",
       "25667  - Wishing a Happy Father's Day to all the Dad'...  2009          124  \n",
       "25668  RE: FB Vanity URLs: SF Chronicle - \"David Beck...  2009          140  \n",
       "25669  Thanks to all for your thoughtful birthday wis...  2009           64  \n",
       "25670  Today is Donald Trump's Birthday! Send him you...  2009          102  \n",
       "25671  Last week to enter the \"Think Like A Champion\"...  2009          128  \n",
       "25672  ‚ÄúIf you don't have problems, you're pretending...  2009          127  \n",
       "25673  Check out Donald Trump's new iGoogle Showcase ...  2009           71  \n",
       "25674  \"You have to know when to call it quits and wh...  2009          130  \n",
       "25675  Read an excerpt from Think Like A Champion by ...  2009           83  \n",
       "25676  \"Your higher self is in direct opposition to y...  2009          108  \n",
       "25677  Did you know Donald Trump is on Facebook? http...  2009           99  \n",
       "25678  Don't forget to enter the \"Think Like A Champi...  2009          130  \n",
       "25679  \"Keep it fast, short and direct - whatever it ...  2009           94  \n",
       "25680  Read a great interview with Donald Trump that ...  2009          112  \n",
       "25681  \"Always know you could be on the precipice of ...  2009          107  \n",
       "25682  \"...these days...we could all use a little of ...  2009          126  \n",
       "25683  \"We win in our lives by having a champion's vi...  2009          109  \n",
       "25684  \"Don‚Äôt be afraid of being unique - it's like b...  2009          121  \n",
       "25685  \"When the achiever achieves, it's not a platea...  2009          111  \n",
       "25686  Enter the \"Think Like A Champion\" signed book ...  2009          115  \n",
       "25687  \"Strive for wholeness and keep your sense of w...  2009          104  \n",
       "25688  Listen to an interview with Donald Trump discu...  2009          114  \n",
       "25689  Miss USA Tara Conner will not be fired - \"I've...  2009          107  \n",
       "25690  \"My persona will never be that of a wallflower...  2009          109  \n",
       "25691  New Blog Post: Celebrity Apprentice Finale and...  2009          103  \n",
       "25692  Donald Trump reads Top Ten Financial Tips on L...  2009          116  \n",
       "25693  Donald Trump will be appearing on The View tom...  2009          131  \n",
       "25694  Be sure to tune in and watch Donald Trump on L...  2009          117  \n",
       "\n",
       "[25695 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['text_length'] = tweets['text'].apply(lambda t : len(t)) \n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F√ºr einen groben √úberblick schauen wir uns einige Kennzahlen zur Textl√§nge an. Dazu gruppieren wir nach ```year```und nutzen dann die ```describe```-Methode des Dataframes, wobei wir nur Spalten vom Typ ```numpy.number``` betrachten und daher der ```describe```-Methode eine entsprechende ```include```-Liste mitgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">text_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>56.0</td>\n",
       "      <td>112.214286</td>\n",
       "      <td>20.056932</td>\n",
       "      <td>62.0</td>\n",
       "      <td>103.75</td>\n",
       "      <td>115.0</td>\n",
       "      <td>126.25</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>142.0</td>\n",
       "      <td>122.528169</td>\n",
       "      <td>21.394536</td>\n",
       "      <td>45.0</td>\n",
       "      <td>111.00</td>\n",
       "      <td>132.5</td>\n",
       "      <td>138.00</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>774.0</td>\n",
       "      <td>107.739018</td>\n",
       "      <td>27.061936</td>\n",
       "      <td>38.0</td>\n",
       "      <td>86.00</td>\n",
       "      <td>114.0</td>\n",
       "      <td>133.00</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>3530.0</td>\n",
       "      <td>106.975921</td>\n",
       "      <td>32.147123</td>\n",
       "      <td>12.0</td>\n",
       "      <td>87.00</td>\n",
       "      <td>117.0</td>\n",
       "      <td>135.00</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>5775.0</td>\n",
       "      <td>86.123983</td>\n",
       "      <td>43.081747</td>\n",
       "      <td>9.0</td>\n",
       "      <td>41.00</td>\n",
       "      <td>94.0</td>\n",
       "      <td>128.00</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>2433.0</td>\n",
       "      <td>114.132758</td>\n",
       "      <td>27.615667</td>\n",
       "      <td>21.0</td>\n",
       "      <td>98.00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>136.00</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>3057.0</td>\n",
       "      <td>109.009486</td>\n",
       "      <td>31.873999</td>\n",
       "      <td>15.0</td>\n",
       "      <td>87.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.00</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>3465.0</td>\n",
       "      <td>113.363925</td>\n",
       "      <td>30.697098</td>\n",
       "      <td>14.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>127.0</td>\n",
       "      <td>138.00</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>2284.0</td>\n",
       "      <td>133.917688</td>\n",
       "      <td>46.279751</td>\n",
       "      <td>2.0</td>\n",
       "      <td>119.00</td>\n",
       "      <td>138.0</td>\n",
       "      <td>143.00</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>3104.0</td>\n",
       "      <td>198.084407</td>\n",
       "      <td>83.564703</td>\n",
       "      <td>8.0</td>\n",
       "      <td>131.00</td>\n",
       "      <td>221.0</td>\n",
       "      <td>277.00</td>\n",
       "      <td>315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>1075.0</td>\n",
       "      <td>183.999070</td>\n",
       "      <td>92.820761</td>\n",
       "      <td>5.0</td>\n",
       "      <td>102.50</td>\n",
       "      <td>205.0</td>\n",
       "      <td>276.00</td>\n",
       "      <td>302.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     text_length                                                           \n",
       "           count        mean        std   min     25%    50%     75%    max\n",
       "year                                                                       \n",
       "2009        56.0  112.214286  20.056932  62.0  103.75  115.0  126.25  140.0\n",
       "2010       142.0  122.528169  21.394536  45.0  111.00  132.5  138.00  140.0\n",
       "2011       774.0  107.739018  27.061936  38.0   86.00  114.0  133.00  140.0\n",
       "2012      3530.0  106.975921  32.147123  12.0   87.00  117.0  135.00  148.0\n",
       "2013      5775.0   86.123983  43.081747   9.0   41.00   94.0  128.00  152.0\n",
       "2014      2433.0  114.132758  27.615667  21.0   98.00  124.0  136.00  148.0\n",
       "2015      3057.0  109.009486  31.873999  15.0   87.00  120.0  137.00  155.0\n",
       "2016      3465.0  113.363925  30.697098  14.0   93.00  127.0  138.00  148.0\n",
       "2017      2284.0  133.917688  46.279751   2.0  119.00  138.0  143.00  320.0\n",
       "2018      3104.0  198.084407  83.564703   8.0  131.00  221.0  277.00  315.0\n",
       "2019      1075.0  183.999070  92.820761   5.0  102.50  205.0  276.00  302.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "tweets.groupby(['year']).describe(include=[numpy.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Top-Hashtags und -Mentions\n",
    "Nachdem wir uns mit der L√§nge der Texte besch√§ftigt haben, wollen wir nun herausfinden, wen Donald Trump in seinen Tweets erw√§hnt und welche Themen er (hash)taggt. Dabei interessiert uns die Entwicklung √ºber die Jahre.\n",
    "\n",
    "Wir beginnen mit den Hashtags und verwenden zun√§chst einen kleinen Trick, um ein Dictionary zu erstellen, das f√ºr jedes Jahr einen \"Sub-Dataframe\" enth√§lt. Diese Dataframes bearbeiten wir dann weiter, indem wir deren ```text```-Felder jeweils zu einem langen String konkatenieren: ```' '.join(frame['text']) for frame in ...```\n",
    "Damit haben wir pro Jahr alle konkatenierten Tweet-Texte, aus denen wir dann die Hashtags extrahieren k√∂nnen. Hierbei machen wir uns noch keine allzu gro√üen Gedanken √ºber Normalisierung, sondern zerlegen die langen Texte in einzelne Tokens, aus denen wir dann die Hashtags herausfiltern. \n",
    "Um die Top-Hashtags in Erfahrung zu bringen, verwenden wir wieder ```Counter```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2009: [],\n",
       " 2010: [('#EvanForSI', 1)],\n",
       " 2011: [('#TimeToGetTough', 45), ('#trumpvlog', 23), ('#trumpvlog...', 11)],\n",
       " 2012: [('#TimeToGetTough', 31), ('#sweepstweet', 19), ('#trumpvlog', 15)],\n",
       " 2013: [('#CelebApprentice', 127), ('#1', 25), ('#WWEHOF', 15)],\n",
       " 2014: [('#Oscars', 18), ('#TBT', 13), ('#TrumpVlog', 12)],\n",
       " 2015: [('#Trump2016', 114),\n",
       "  ('#MakeAmericaGreatAgain', 104),\n",
       "  ('#MakeAmericaGreatAgain!', 19)],\n",
       " 2016: [('#Trump2016', 314),\n",
       "  ('#MakeAmericaGreatAgain', 204),\n",
       "  ('#AmericaFirst', 71)],\n",
       " 2017: [('#USAüá∫üá∏', 23), ('#MAGA', 13), ('#MAGAüá∫üá∏', 12)],\n",
       " 2018: [('#MAGA', 55), ('#MAGAüá∫üá∏', 15), ('#1', 6)],\n",
       " 2019: [('#MAGA', 14), ('#TakeBackDay', 2), ('#MAGAüá∫üá∏', 2)]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tweets_by_year = dict(list(tweets.groupby(['year'])))\n",
    "texts_per_year = {year:' '.join(frame['text']) for year, frame in tweets_by_year.items()}\n",
    "top_hashtags_per_year = {year: Counter([token for token in texts.split() if token.startswith('#')]).most_common(3) for year, texts in texts_per_year.items()}\n",
    "top_hashtags_per_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als n√§chstes interessieren uns die Mentions. Wir k√∂nnen hier analog zu den Hashtags vorgehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2009: [('@IvankaTrump', 1)],\n",
       " 2010: [('@kingsthings', 1), ('@hollyrpeete', 1)],\n",
       " 2011: [('@BarackObama', 115), ('@FoxNews', 16), (\"@BarackObama's\", 15)],\n",
       " 2012: [('@BarackObama', 347), ('@MittRomney', 179), (\"@BarackObama's\", 104)],\n",
       " 2013: [('@ApprenticeNBC', 73), ('@billmaher', 56), ('@CelebApprentice', 37)],\n",
       " 2014: [('@foxandfriends', 26), ('@TrumpDoral', 24), ('@AGSchneiderman', 20)],\n",
       " 2015: [('@FoxNews', 56), ('@CNN', 45), ('@foxandfriends', 37)],\n",
       " 2016: [('@CNN', 54), ('@FoxNews', 43), ('@nytimes', 42)],\n",
       " 2017: [('@foxandfriends', 35), ('@WhiteHouse', 25), ('@nytimes', 21)],\n",
       " 2018: [('@FoxNews', 55), ('@foxandfriends', 41), ('@WhiteHouse!', 16)],\n",
       " 2019: [('@FoxNews', 27), ('@foxandfriends', 24), ('@seanhannity', 10)]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_mentions_per_year = {year: Counter([token for token in texts.split() if len(token) > 1 and token.startswith('@')]).most_common(3) for year, texts in texts_per_year.items()}\n",
    "top_mentions_per_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Vokabular\n",
    "Bevor wir endg√ºltig auf die Ebene der Einzelzeichen herabsteigen, wollen wir uns das von Trump verwendete Vokabular genauer ansehen und dabei auch herausfinden, ob weitere Vorverarbeitungsschritte n√∂tig sind.\n",
    "\n",
    "Dazu erstellen wir uns zun√§chst eine Liste aller Tokens, die in den Dokumenten vorkommen. Wir gruppieren nicht mehr per Jahr, sondern gehen ganz simpel vor und konkatenieren alle Tweet-Texte in einen langen String, den wir dann in einzelne Terme splitten.\n",
    "\n",
    "Gebt die 20 h√§ufigsten Terme aus. Was f√§llt auf (insbesondere bei Betrachtung des hinteren Endes der Liste)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 17252),\n",
       " ('to', 11653),\n",
       " ('and', 9303),\n",
       " ('of', 8246),\n",
       " ('a', 7975),\n",
       " ('is', 7535),\n",
       " ('in', 6777),\n",
       " ('for', 5067),\n",
       " ('I', 4861),\n",
       " ('on', 4842),\n",
       " ('be', 4023),\n",
       " ('will', 3761),\n",
       " ('that', 3217),\n",
       " ('are', 3177),\n",
       " ('with', 2980),\n",
       " ('you', 2963),\n",
       " ('at', 2800),\n",
       " ('&amp;', 2764),\n",
       " ('The', 2759),\n",
       " ('have', 2546)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_texts = ' '.join(tweets['text'])\n",
    "tokens = tweet_texts.split();\n",
    "\n",
    "Counter(tokens).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welche Nachbarbeitungsschritte k√∂nnten im Hinblick auf die sp√§tere Verarbeitung einzelner Zeichen sinnvoll sein?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "cleaned_tweet_texts = html.unescape(tweet_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exkursion: SpaCy\n",
    "\n",
    "[```spaCy```](https://spacy.io/) ist eine recht verbreitete Bibliothek im Bereich NLP. Um damit erste Erfahrungen zu sammeln, tokenisieren wir unsere Texte unter Verwendung des ```nlp```-Objekts erneut und filtern alle Satzzeichen und Stopw√∂rter aus. Aus Performancegr√ºnden verarbeiten wir die Texte nacheinander und nicht den konkatenierten Gesamttext.\n",
    "\n",
    "Was f√§llt bei der Betrachtung der Top Tokens auf?\n",
    "\n",
    "**Hinweise**\n",
    "1. Benutzung von ```spaCy```: ```spaCy``` versieht die Tokens mit zus√§tzlichen Informationen zum Beispiel dar√ºber, ob es sich bei dem Token um ein Stopwort oder ein Satzzeichen handelt (https://spacy.io/api/token). Wenn wir nur am Text interessiert sind, k√∂nnen wir auf diesen mittels ```token.text``` zugreifen. Ob es sich um ein Stopwort handelt, verr√§t ```token.is_stop```, ```token.is_punct``` gibt zur√ºck, ob es sich bei dem entsprechenden Token um ein Satzzeichen handelt.\n",
    "2. Aufwand: Beim Betrachten der Top 20 Tokens sollte deutlich werden, dass auch der R√ºckgriff auf \"Out-of-the-box\"-L√∂sungen nicht hei√üt, dass Nachdenken unn√∂tig wird. Wir wollen das aber an dieser Stelle nicht weiter vertiefen, weil wir ohnehin auf Zeichenebene arbeiten wollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 5648),\n",
       " (' ', 3628),\n",
       " ('The', 3088),\n",
       " ('great', 2415),\n",
       " (\"'s\", 2179),\n",
       " ('Trump', 2125),\n",
       " ('‚Äôs', 1568),\n",
       " ('\\n', 1566),\n",
       " ('people', 1490),\n",
       " ('Obama', 1412),\n",
       " (\"n't\", 1404),\n",
       " ('Thank', 1313),\n",
       " ('We', 1292),\n",
       " ('It', 989),\n",
       " ('Great', 985),\n",
       " ('n‚Äôt', 982),\n",
       " ('time', 920),\n",
       " ('Thanks', 891),\n",
       " ('He', 882),\n",
       " ('A', 875)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en', disable=['ner', 'tagger', 'parser', 'textcat'])\n",
    "tweet_list = list(tweets['text'])\n",
    "nlp_docs = [nlp(html.unescape(tweet)) for tweet in tweet_list]\n",
    "nlp_annotated_tokens = [token for doc in nlp_docs for token in doc]\n",
    "nlp_tokens = [token.text for token in nlp_annotated_tokens if not token.is_stop and not token.is_punct]\n",
    "Counter(nlp_tokens).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Verwendete Zeichen\n",
    "Zum Ende unserer Analysephase schauen wir uns noch an, welche Einzelzeichen in den Tweets vorkommen. Dazu greifen wir wieder auf die konkatenierten (und bereinigten) Tweettexte zur√ºck, die in der Variable ```cleaned_tweet_texts``` gespeichert sind.\n",
    "Wie viele Zeichen gibt es und wie h√§ufig werden sie verwendet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 500248),\n",
       " ('e', 251197),\n",
       " ('t', 203968),\n",
       " ('a', 181386),\n",
       " ('o', 180107),\n",
       " ('n', 156202),\n",
       " ('i', 152156),\n",
       " ('r', 141102),\n",
       " ('s', 130437),\n",
       " ('h', 99586),\n",
       " ('l', 95030),\n",
       " ('d', 73567),\n",
       " ('u', 64669),\n",
       " ('c', 63887),\n",
       " ('m', 56675),\n",
       " ('g', 50691),\n",
       " ('p', 50529),\n",
       " ('y', 49148),\n",
       " ('.', 44782),\n",
       " ('w', 42146),\n",
       " ('f', 37350),\n",
       " ('b', 36134),\n",
       " ('/', 25392),\n",
       " ('v', 23573),\n",
       " ('k', 23007),\n",
       " ('T', 22293),\n",
       " ('A', 18312),\n",
       " (',', 17799),\n",
       " ('I', 15825),\n",
       " ('C', 15356),\n",
       " ('S', 15184),\n",
       " ('@', 13742),\n",
       " ('!', 13161),\n",
       " ('M', 12357),\n",
       " ('N', 11580),\n",
       " (':', 10938),\n",
       " ('R', 10460),\n",
       " ('O', 10206),\n",
       " ('E', 10181),\n",
       " ('W', 9758),\n",
       " ('B', 9570),\n",
       " ('-', 9134),\n",
       " ('D', 8983),\n",
       " ('P', 8822),\n",
       " ('G', 8544),\n",
       " ('H', 8113),\n",
       " ('L', 6885),\n",
       " ('F', 6682),\n",
       " ('0', 6599),\n",
       " ('x', 5871),\n",
       " (\"'\", 5395),\n",
       " ('1', 5278),\n",
       " ('j', 5251),\n",
       " ('U', 5235),\n",
       " ('J', 5181),\n",
       " ('V', 4327),\n",
       " ('2', 4030),\n",
       " ('Y', 4007),\n",
       " ('\"', 3794),\n",
       " ('#', 3736),\n",
       " ('z', 3706),\n",
       " ('K', 3686),\n",
       " ('‚Äô', 3316),\n",
       " ('&', 2884),\n",
       " ('3', 2617),\n",
       " ('6', 2603),\n",
       " ('5', 2577),\n",
       " ('7', 2370),\n",
       " ('4', 2253),\n",
       " ('q', 2209),\n",
       " ('8', 2141),\n",
       " ('9', 2131),\n",
       " ('\\n', 2103),\n",
       " ('‚Äú', 2008),\n",
       " ('‚Äù', 1995),\n",
       " ('?', 1952),\n",
       " (')', 1646),\n",
       " ('(', 1641),\n",
       " ('Z', 1509),\n",
       " ('Q', 1436),\n",
       " ('X', 1401),\n",
       " ('_', 901),\n",
       " ('$', 778),\n",
       " ('%', 649),\n",
       " ('‚Äî', 535),\n",
       " ('‚Ä¶', 441),\n",
       " ('‚Äì', 440),\n",
       " ('‚Äò', 203),\n",
       " ('üá∏', 154),\n",
       " ('üá∫', 153),\n",
       " ('Ô∏è', 61),\n",
       " (';', 47),\n",
       " ('‚û°', 45),\n",
       " ('=', 44),\n",
       " ('\\xa0', 42),\n",
       " ('+', 39),\n",
       " ('üé•', 15),\n",
       " ('‚ùå', 14),\n",
       " ('ÿß', 12),\n",
       " ('‚úÖ', 12),\n",
       " ('|', 11),\n",
       " ('ÿ≥', 11),\n",
       " ('ÿ±', 11),\n",
       " ('üáµ', 11),\n",
       " ('‚Ä¢', 11),\n",
       " ('üá∑', 10),\n",
       " ('‚òë', 10),\n",
       " ('*', 9),\n",
       " ('√©', 9),\n",
       " ('~', 9),\n",
       " ('ÿØ', 8),\n",
       " ('ÿ™', 8),\n",
       " ('üìà', 8),\n",
       " ('ŸÜ', 7),\n",
       " ('Ÿá', 7),\n",
       " ('\\r', 7),\n",
       " ('€å', 6),\n",
       " ('üáØ', 6),\n",
       " ('>', 6),\n",
       " ('ŸÑ', 5),\n",
       " ('ŸÖ', 5),\n",
       " ('¬£', 5),\n",
       " ('¬Æ', 5),\n",
       " ('‚òÖ', 5),\n",
       " ('Ÿà', 4),\n",
       " ('ÿ¥', 4),\n",
       " ('üá®', 4),\n",
       " ('üá¶', 4),\n",
       " ('üáÆ', 4),\n",
       " ('üá™', 4),\n",
       " ('üá∞', 4),\n",
       " ('üì∏', 4),\n",
       " ('¬∫', 4),\n",
       " ('€¥', 3),\n",
       " ('€∞', 3),\n",
       " ('⁄©', 3),\n",
       " ('{', 3),\n",
       " ('}', 3),\n",
       " ('‚öæ', 3),\n",
       " ('‚Äï', 3),\n",
       " ('‚òò', 2),\n",
       " ('ŸÅ', 2),\n",
       " ('ÿ®', 2),\n",
       " ('ÿ¨', 2),\n",
       " ('üá≤', 2),\n",
       " ('üáπ', 2),\n",
       " ('üá¨', 2),\n",
       " ('√≥', 2),\n",
       " ('üá≥', 2),\n",
       " ('üá´', 2),\n",
       " ('üèÜ', 2),\n",
       " ('üá¥', 2),\n",
       " ('√â', 2),\n",
       " ('≈ç', 2),\n",
       " ('üá±', 2),\n",
       " ('üö®', 2),\n",
       " ('\\u200e', 2),\n",
       " ('\\u200f', 2),\n",
       " ('⁄ò', 1),\n",
       " ('ŸÇ', 1),\n",
       " ('ÿ∑', 1),\n",
       " ('⁄Ü', 1),\n",
       " ('ÿ¢', 1),\n",
       " ('üíØ', 1),\n",
       " ('üáΩ', 1),\n",
       " ('üéÑ', 1),\n",
       " ('üáß', 1),\n",
       " ('‚ûú', 1),\n",
       " ('üìâ', 1),\n",
       " ('üíú', 1),\n",
       " ('üí∞', 1),\n",
       " ('üèà', 1),\n",
       " ('·ªÖ', 1),\n",
       " ('√¢', 1),\n",
       " ('√∫', 1),\n",
       " ('ƒü', 1),\n",
       " ('√∏', 1),\n",
       " ('√°', 1),\n",
       " ('‚úî', 1),\n",
       " ('‚¨á', 1),\n",
       " ('\\U0010fc00', 1),\n",
       " ('√±', 1),\n",
       " ('√≠', 1),\n",
       " ('[', 1),\n",
       " (']', 1),\n",
       " ('„Ää', 1),\n",
       " ('\\u200b', 1),\n",
       " ('`', 1),\n",
       " ('‚Ä≤', 1),\n",
       " ('<', 1),\n",
       " ('‚Ñ¢', 1),\n",
       " ('üëç', 1),\n",
       " ('‚ù§', 1),\n",
       " ('\\\\', 1),\n",
       " ('‚Ç¨', 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_chars = list(cleaned_tweet_texts)\n",
    "char_counter = Counter(tweet_chars)\n",
    "num_chars = len(set(char_counter.keys()))\n",
    "char_counter.most_common(num_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Vom Text zur Zeichenliste\n",
    "Betrachten Sie die in der vorherigen Teilaufgabe generierte Liste der verwendeten Zeichen. Welche Bereinigungsschritte k√∂nnten angemessen sein? Kurze Begr√ºndung bitte.\n",
    "\n",
    "Bevor wir daran gehen, vektorisierte Trainingsdaten f√ºr unser Modell zu generieren, wandeln wir unsere Tweets in dieser Teilaufgabe in eine (bereinigte) Liste von Einzelzeichen um und speichern diese in der Variable ```cleaned_tweet_chars```.\n",
    "\n",
    "```['d', 'i', 'e', 's', ' ', 'i', 's', 't', ' ', 'e', 'i', 'n', ' ', 'b', 'e', 'i', 's', 'p', 'i', 'e', 'l', ',', ' ', 'w', 'i', 'e', ' ', 'd', 'i', 'e', ' ', 'l', 'i', 's', 't', 'e', ' ', 'b', 'e', 'g', 'i', 'n', 'n', 'e', 'n', ' ', 'k', '√∂', 'n', 'n', 't', 'e', '.']```\n",
    "\n",
    "\n",
    "**Hinweise**: \n",
    "* In Python gibt es eine Methode ```str.isprintable()```, die bei der Bereinigung hilfreich sein k√∂nnte ...\n",
    "* Vereinfachung ist legitim. Je mehr Einzelzeichen wir bei der Modellierung ber√ºcksichtigen, umso komplexer wird unser Modell und umso h√∂her ist der Trainingsaufwand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 500248),\n",
       " ('e', 261378),\n",
       " ('t', 226261),\n",
       " ('a', 199698),\n",
       " ('o', 190313),\n",
       " ('i', 167981),\n",
       " ('n', 167782),\n",
       " ('r', 151562),\n",
       " ('s', 145621),\n",
       " ('h', 107699),\n",
       " ('l', 101915),\n",
       " ('d', 82550),\n",
       " ('c', 79243),\n",
       " ('u', 69904),\n",
       " ('m', 69032),\n",
       " ('p', 59351),\n",
       " ('g', 59235),\n",
       " ('y', 53155),\n",
       " ('w', 51904),\n",
       " ('b', 45704),\n",
       " ('.', 44782),\n",
       " ('f', 44032),\n",
       " ('v', 27900),\n",
       " ('k', 26693),\n",
       " ('/', 25392),\n",
       " (',', 17799),\n",
       " ('@', 13742),\n",
       " ('!', 13161),\n",
       " (':', 10938),\n",
       " ('j', 10432),\n",
       " ('-', 9134),\n",
       " ('x', 7272),\n",
       " ('0', 6599),\n",
       " (\"'\", 5395),\n",
       " ('1', 5278),\n",
       " ('z', 5215),\n",
       " ('2', 4030),\n",
       " ('\"', 3794),\n",
       " ('#', 3736),\n",
       " ('q', 3645),\n",
       " ('‚Äô', 3316),\n",
       " ('&', 2884),\n",
       " ('3', 2617),\n",
       " ('6', 2603),\n",
       " ('5', 2577),\n",
       " ('7', 2370),\n",
       " ('4', 2253),\n",
       " ('8', 2141),\n",
       " ('9', 2131),\n",
       " ('‚Äú', 2008),\n",
       " ('‚Äù', 1995),\n",
       " ('?', 1952),\n",
       " (')', 1646),\n",
       " ('(', 1641),\n",
       " ('_', 901),\n",
       " ('$', 778),\n",
       " ('%', 649),\n",
       " ('‚Äî', 535),\n",
       " ('‚Ä¶', 441),\n",
       " ('‚Äì', 440),\n",
       " ('‚Äò', 203)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_tweet_chars = [char.lower() for char in tweet_chars if char.isprintable() and char_counter[char] >= 200]\n",
    "Counter(cleaned_tweet_chars).most_common(num_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2\n",
    "Nachdem wir uns einen √úberblick √ºber den Datensatz verschafft und uns f√ºr die Zeichen entschieden haben, die wir bei der Modellierung ber√ºcksichtigen wollen, geht es nun darum, die Daten so aufzubereiten, dass wir ein Modell trainieren k√∂nnen.\n",
    "\n",
    "Das Training soll wie folgt ablaufen: Gegeben 30 Zeichen, soll das Modell das 31. Zeichen vorhersagen. Dazu m√ºssen wir die einzelnen Zeichen in Vektorform bringen. Wir w√§hlen dazu ein One-Hot-Encoding und bilden folglich jedes der Einzelzeichen in ```tweet_chars_cleaned``` auf einen Vektor ab, der genau eine 1 enth√§lt.\n",
    "\n",
    "(Zu) einfaches Beispiel: ```['a', 'b', 'c'] => [(1,0,0), (0,1,0), (0,0,1)]```\n",
    "\n",
    "### 2.1 Indizes f√ºr das One-Hot-Encoding\n",
    "Um entscheiden zu k√∂nnen, an welcher Stelle wir die 1 setzen, m√ºssen wir jedem Zeichen einen eindeutigen Index zuweisen.\n",
    "Umgekehrt wollen wir auch zu jedem Index schnell das zugeh√∂rige Zeichen ermitteln k√∂nnen. Wir erstellen daher zwei Dictionaries: ```char2index``` f√ºr die Abbildung von Zeichen zu Index und ```index2char``` f√ºr die umgekehrte Abbildung von Index zu Zeichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Zeichen: 61\n"
     ]
    }
   ],
   "source": [
    "char_set = set(cleaned_tweet_chars)\n",
    "print('Anzahl Zeichen: {}'.format(len(char_set)))\n",
    "char2index = dict((c, i) for i, c in enumerate(char_set))\n",
    "index2char = dict((i, c) for i, c in enumerate(char_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Generiere Trainingsdaten\n",
    "Wie bereits beschrieben, soll das Modell 30 Zeichen entgegennehmen und das 31. Zeichen vorhersagen. Wir generieren uns Trainingsdaten, indem wir ```sentences``` eine Liste von 30 Zeichen aus ```cleaned_tweet_chars``` hinzuf√ºgen, ```next_chars``` das darauf folgende 31. Zeichen und dies alle 4 Zeichen wiederholen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Trainingss√§tze: 778889\n"
     ]
    }
   ],
   "source": [
    "input_length = 30\n",
    "step = 4\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(cleaned_tweet_chars) - input_length, step):\n",
    "    sentences.append(cleaned_tweet_chars[i: i + input_length])\n",
    "    next_chars.append(cleaned_tweet_chars[i + input_length])\n",
    "print('Anzahl Trainingss√§tze: {}'.format(len(sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Vektorisierung\n",
    "Nun k√∂nnen wir daran gehen, die Daten zu vektorisieren. Die Eingabe ```x``` enth√§lt f√ºr jeden der Trainingss√§tze in ```sentences``` 30 one-hot-encodierte Vektoren. Die erwartete Ausgabe basiert auf ```next_chars``` und enth√§lt f√ºr jeden der Trainingss√§tze einen einzelnen one-hot-encodierten Vektor f√ºr das als Fortsetzung des Satzes erwartete Zeichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vektorisierung ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('Vektorisierung ...')\n",
    "x = np.zeros((len(sentences), input_length, len(char_set)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(char_set)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char2index[char]] = 1\n",
    "    y[i, char2index[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Definition des Modells\n",
    "\n",
    "F√ºr unseren Tweet-Generator werden wir ein recht einfaches Modell trainieren. Wir verwenden wieder die Sequential-API. \n",
    "\n",
    "Der erste Layer ist direkt das Herzst√ºck unseres Modells: Der LSTM-Layer. \n",
    "\n",
    "Als Anzahl der Units verwenden wir 128.\n",
    "Welche Dimensionen hat die ```input_shape```? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erstelle Model...\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import metrics\n",
    "\n",
    "print('Erstelle Model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(input_length, len(char_set))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Ausgabelayer f√ºgen wir einen Dense-Layer hinzu. Wie m√ºssen wir die Anzahl der Hidden-Units w√§hlen? Wieso ist ```softmax``` eine geeignete Aktivierungsfunktion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(len(char_set), activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Optimizer w√§hlen wir RMSprop mit einer Learning-Rate von 0.003 und als Loss-Funktion ```categorical_crossentropy```.\n",
    "\n",
    "Wieso k√∂nnen wir nicht wie im letzten Labor ```binary_crossentropy``` verwenden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               97280     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 61)                7869      \n",
      "=================================================================\n",
      "Total params: 105,149\n",
      "Trainable params: 105,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=0.003)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Zusammenhang mit LSTMs werden h√§ufig Dropout-Layer erw√§hnt. Bei Betrachtung der Zusammenfassung unseres Modells f√§llt auf, dass wir keinen solchen Layer verwenden.\n",
    "\n",
    "Wozu dienen Dropout-Layer? Warum k√∂nnte es in unserem Fall angemessen sein, auf einen solchen Layer zu verzichten?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Training des Modells\n",
    "\n",
    "Nach all den Vorarbeiten k√∂nnen wir nun daran gehen, unser Modell zu trainieren.\n",
    "Um das Modell bei Bedarf nicht neu definieren zu m√ºssen, speichern wir uns dessen Struktur als JSON ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_structure = model.to_json()\n",
    "with open(\"text_generation_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um unsere Trainingsfortschritte nicht zu verlieren, definieren wir uns eine Checkpoint-Funktion, die als Callback aufgerufen wird und den aktuellen Modellzustand abspeichert, solange das Modell besser ist, als das bisher gespeicherte Modell. Gespeichert werden soll das komplette Modell, nicht nur die Gewichte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "model_checkpoint = ModelCheckpoint('text_generation.hd5', monitor='loss', save_best_only=True, save_weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt wird es ernst. Wir trainieren unser Modell. Um in ansehbarer Zeit Ergebnisse zu sehen, f√ºhren wir unser Training √ºber 20 Epochen mit eine Batch-Size von 100 durch.\n",
    "\n",
    "Um die Entwicklung des Modells sp√§ter auswerten zu k√∂nnen, speichern wir uns die Model-History."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "778889/778889 [==============================] - 1104s 1ms/step - loss: 1.9623 - acc: 0.4465\n",
      "Epoch 2/20\n",
      "778889/778889 [==============================] - 1102s 1ms/step - loss: 1.6573 - acc: 0.5305\n",
      "Epoch 3/20\n",
      "778889/778889 [==============================] - 1093s 1ms/step - loss: 1.5863 - acc: 0.5493\n",
      "Epoch 4/20\n",
      "778889/778889 [==============================] - 1099s 1ms/step - loss: 1.5479 - acc: 0.5598\n",
      "Epoch 5/20\n",
      "778889/778889 [==============================] - 1098s 1ms/step - loss: 1.5234 - acc: 0.5661\n",
      "Epoch 6/20\n",
      "778889/778889 [==============================] - 1103s 1ms/step - loss: 1.5066 - acc: 0.5707\n",
      "Epoch 7/20\n",
      "778889/778889 [==============================] - 1108s 1ms/step - loss: 1.4930 - acc: 0.5743\n",
      "Epoch 8/20\n",
      "778889/778889 [==============================] - 1108s 1ms/step - loss: 1.4832 - acc: 0.5769\n",
      "Epoch 9/20\n",
      "778889/778889 [==============================] - 1111s 1ms/step - loss: 1.4761 - acc: 0.5791\n",
      "Epoch 10/20\n",
      "778889/778889 [==============================] - 1113s 1ms/step - loss: 1.4708 - acc: 0.5802\n",
      "Epoch 11/20\n",
      "778889/778889 [==============================] - 1105s 1ms/step - loss: 1.4647 - acc: 0.5817\n",
      "Epoch 12/20\n",
      "778889/778889 [==============================] - 1105s 1ms/step - loss: 1.4605 - acc: 0.5829\n",
      "Epoch 13/20\n",
      "778889/778889 [==============================] - 1115s 1ms/step - loss: 1.4572 - acc: 0.5842\n",
      "Epoch 14/20\n",
      "778889/778889 [==============================] - 1112s 1ms/step - loss: 1.4541 - acc: 0.5852\n",
      "Epoch 15/20\n",
      "778889/778889 [==============================] - 1113s 1ms/step - loss: 1.4519 - acc: 0.5860\n",
      "Epoch 16/20\n",
      "778889/778889 [==============================] - 1110s 1ms/step - loss: 1.4504 - acc: 0.5862\n",
      "Epoch 17/20\n",
      "778889/778889 [==============================] - 1116s 1ms/step - loss: 1.4486 - acc: 0.5870\n",
      "Epoch 18/20\n",
      "778889/778889 [==============================] - 1114s 1ms/step - loss: 1.4466 - acc: 0.5873\n",
      "Epoch 19/20\n",
      "778889/778889 [==============================] - 1114s 1ms/step - loss: 1.4449 - acc: 0.5885\n",
      "Epoch 20/20\n",
      "778889/778889 [==============================] - 1125s 1ms/step - loss: 1.4438 - acc: 0.5885\n",
      "History saved.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "model_history = model.fit(x, y, batch_size=batch_size, epochs=epochs, callbacks=[model_checkpoint])\n",
    "\n",
    "with open(\"text_generation_history\", 'wb') as hist_file:\n",
    "    pickle.dump(model_history.history, hist_file)\n",
    "print('History saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 3\n",
    "Zum Abschluss wollen wir noch etwas Spa√ü mit unserem Modell haben. Aus diesem Grund laden wir uns das gespeicherte (bisher) beste Model und verwenden es, um basierend auf einem \"Seed\" neue Tweets zu generieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "loaded_model = load_model('text_generation.hd5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eine kleine Hilfsfunktion\n",
    "Der Ausgabelayer unseres Models beschreibt eine Wahrscheinlichkeitsverteilung √ºber alle m√∂glichen Ausgabezeichen. Was wir tun wollen, ist anhand dieser Verteilung eine repr√§sentative Stichprobe zu ziehen. √Ñhnlich wie bei Markov-Ketten w√§hlen wir als n√§chstes Zeichen nicht zwangsl√§ufig das, mit der h√∂chsten Auftrittswahrscheinlichkeit, denn wir wollen uns ja eine gewissen k√ºnstlerisch-kreative Freiheit erhalten, aber wir orientieren uns bei der Auswahl an der Auftrittswahrscheinlichkeit der potentiellen Folgetokens im gegebenen Kontext.\n",
    "\n",
    "Die Hilfsmethode, die wir dazu verwenden, ist aus dem Keras-Tutorial zu LSTMs √ºbernommen. Der Parameter ```temperature``` sch√§rft die urspr√ºngliche Wahrscheinlichkeitsverteilung oder schw√§cht sie ab. Bei ```temperature > 1``` ist die Ausgabe diverser, allerdings potentiell auch konfuser, bei ```temperature < 1 ``` bleiben wir n√§her an den Originaltweets.\n",
    "\n",
    "```multinominal(num_samples, probabilities_list, size``` zieht ```size```-mal ```num_samples``` Beispiele aus einer Verteilung, deren Eigenschaften durch ```probabilities_list``` beschrieben wird. In unserem Fall wollen wir einmal ziehen und zwar genau ein Beispiel. Ausgabe ist demnach eine Liste, die einen einzigen Vektor enth√§lt, der genauso lang ist, wie die Wahrscheinlichkeitsverteilung, die wir in die Funktion hineingeben, und der eine einzige 1 enth√§lt. F√ºr den Index dieser 1 interessieren wir uns, weil wir das entsprechend one-hot-codierte Zeichen als n√§chstes ausgeben wollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds.clip(min=0.0001)) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Tweets erzeugen\n",
    "Um neue Tweets zu erzeugen, brauchen wir einen Seed, mit dem unser Model arbeiten kann. Wir machen es uns einfach und w√§hlen einen zuf√§lligen Startindex, ab dem ```input_length``` Zeichen aus unserer langen Tweet-Liste herausgenommen werden.\n",
    "\n",
    "Diese vektorisieren wir dann und f√ºttern unser Model mit dem so entstandenen Vektor, um das n√§chste Zeichen vorherzusagen, das dann wiederum Teil des Seeds f√ºr die n√§chste Vorhersage ist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Diversit√§t: 0.2\n",
      "----- Erzeuge Tweet aus Seed: \"ad hillary clinton and the dem\"\n",
      "\n",
      "ad hillary clinton and the democrats are strong of the debate the pressice and the countries and in the state of the president obama is a great state of the part of the countries and the people and the democrats are strong and the people with the press could not be a great party \n",
      "\n",
      "----- Diversit√§t: 0.5\n",
      "----- Erzeuge Tweet aus Seed: \"ad hillary clinton and the dem\"\n",
      "\n",
      "ad hillary clinton and the democrats not a great poll is a really said with @trumpdoral defend to i am a tariffs the protests to distract leaders and send not on the heroes to still under twitter the record with states and the streets been order to start a republican security sta\n",
      "\n",
      "----- Diversit√§t: 0.8\n",
      "----- Erzeuge Tweet aus Seed: \"ad hillary clinton and the dem\"\n",
      "\n",
      "ad hillary clinton and the democrats historciurs and condest check to help has the new countrial of the fbice for bernie on the deal if you are never brielting other really being to america's never work hoax?hom speechment. he celebrate budgette in so building the unede and you a\n",
      "\n",
      "----- Diversit√§t: 1.0\n",
      "----- Erzeuge Tweet aus Seed: \"ad hillary clinton and the dem\"\n",
      "\n",
      "ad hillary clinton and the demond he else president our improciends owning city with dyincully @mardinhttps://t.co/cxuzefup%z @scamp pipoliel and won with companiev and th‚Ä¶ https://t.co/p whfake now feature or housn or work our ready of america, mallrebord in. rove two prepare! h\n",
      "\n",
      "----- Diversit√§t: 1.2\n",
      "----- Erzeuge Tweet aus Seed: \"ad hillary clinton and the dem\"\n",
      "\n",
      "ad hillary clinton and the demg - ... obamacare! if thewkens celebration, working \"in voted long tomorroe exparningstak! just seredors refusence to 20nr sods. itve very 5buy the fbi clear-pow unnecance about bush a big wartt‚Äîthe real cuting my fector if jeb is ‚Äîdid as photo for o\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "seed_start_index = random.randint(0, len(cleaned_tweet_chars) - input_length - 1)\n",
    "\n",
    "for diversity in [0.2, 0.5, 0.8, 1.0, 1.2]:\n",
    "    print()\n",
    "    print('----- Diversit√§t:', diversity)\n",
    "\n",
    "    generated = ''\n",
    "    sentence = cleaned_tweet_chars[seed_start_index : seed_start_index + input_length]\n",
    "    generated += ''.join(sentence)\n",
    "    print('----- Erzeuge Tweet aus Seed: \"' + ''.join(sentence) + '\"\\n')\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(250):\n",
    "        x = np.zeros((1, input_length, len(char_set)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char2index[char]] = 1.\n",
    "\n",
    "        preds = loaded_model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = index2char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + [next_char]\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input arrays should have the same number of samples as target arrays. Found 1 input samples and 778889 target samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5f99aa7eeb55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/lab/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/lab/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    802\u001b[0m             ]\n\u001b[1;32m    803\u001b[0m             \u001b[0;31m# Check that all arrays have the same length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0mcheck_array_length_consistency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m                 \u001b[0;31m# Additional checks to avoid users mistakenly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/lab/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_array_length_consistency\u001b[0;34m(inputs, targets, weights)\u001b[0m\n\u001b[1;32m    235\u001b[0m                          \u001b[0;34m'the same number of samples as target arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                          \u001b[0;34m'Found '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' input samples '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                          'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         raise ValueError('All sample_weight arrays should have '\n",
      "\u001b[0;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 1 input samples and 778889 target samples."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Entwicklung von Loss und Accuracy\n",
    "Um die Aufgabe abzuschlie√üen, wollen wir noch einen Blick auf die Entwicklung von Loss und Accuracy √ºber die Trainingsepochen werfen. Wir haben die \"Geschichte\" unseres Models in der Datei ```text_generation_history``` abgespeichert.\n",
    "\n",
    "Nutzt ```pyplot```, um die Entwicklung von Accuracy und Loss grafisch darzustellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(\"text_generation_history\", 'rb') as hist_file:\n",
    "    history = pickle.load(hist_file)\n",
    "    \n",
    "plt.plot(history['acc'])\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history['loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
